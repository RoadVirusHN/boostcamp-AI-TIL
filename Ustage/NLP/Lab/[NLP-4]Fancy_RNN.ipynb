{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"4_fancy_rnn.ipynb의 사본","provenance":[{"file_id":"1DwMbVf9KVvWtGz_rGyhM1uXkmc33JUlM","timestamp":1613456383552}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0M47aJDTXtbL"},"source":["##**4. LSTM, GRU**\r\n","1. 기존 RNN과 다른 부분에 대해서 배웁니다.\r\n","2. 이전 실습에 이어 다양한 적용법을 배웁니다."]},{"cell_type":"markdown","metadata":{"id":"jBoAWPAJSI2D"},"source":["### **필요 패키지 import**"]},{"cell_type":"code","metadata":{"id":"vEnlDHarWusL"},"source":["from tqdm import tqdm\r\n","from torch import nn\r\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\r\n","\r\n","import torch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sze4MVwxSYPR"},"source":["### **데이터 전처리**"]},{"cell_type":"markdown","metadata":{"id":"ugKWDpQrSY3o"},"source":["아래의 sample data를 확인해봅시다.  \r\n","이전 실습과 동일합니다."]},{"cell_type":"code","metadata":{"id":"IWjwZOmGYMhw"},"source":["vocab_size = 100\r\n","pad_id = 0\r\n","\r\n","data = [\r\n","  [85,14,80,34,99,20,31,65,53,86,3,58,30,4,11,6,50,71,74,13],\r\n","  [62,76,79,66,32],\r\n","  [93,77,16,67,46,74,24,70],\r\n","  [19,83,88,22,57,40,75,82,4,46],\r\n","  [70,28,30,24,76,84,92,76,77,51,7,20,82,94,57],\r\n","  [58,13,40,61,88,18,92,89,8,14,61,67,49,59,45,12,47,5],\r\n","  [22,5,21,84,39,6,9,84,36,59,32,30,69,70,82,56,1],\r\n","  [94,21,79,24,3,86],\r\n","  [80,80,33,63,34,63],\r\n","  [87,32,79,65,2,96,43,80,85,20,41,52,95,50,35,96,24,80]\r\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FmqlfxW_Tsfm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613457001709,"user_tz":-540,"elapsed":4162,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"ff794ae6-c539-4459-e1cb-874aa17c143c"},"source":["max_len = len(max(data, key=len))\r\n","print(f\"Maximum sequence length: {max_len}\")\r\n","\r\n","valid_lens = []\r\n","for i, seq in enumerate(tqdm(data)):\r\n","  valid_lens.append(len(seq))\r\n","  if len(seq) < max_len:\r\n","    data[i] = seq + [pad_id] * (max_len - len(seq))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 10/10 [00:00<00:00, 30795.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["Maximum sequence length: 20\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"znWCR7UbTvVE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613457001710,"user_tz":-540,"elapsed":4161,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"f0b8f403-c2c5-4f0b-a241-afdd52a6b344"},"source":["# B: batch size, L: maximum sequence length\r\n","batch = torch.LongTensor(data)  # (B, L)\r\n","batch_lens = torch.LongTensor(valid_lens)  # (B)\r\n","\r\n","batch_lens, sorted_idx = batch_lens.sort(descending=True)\r\n","batch = batch[sorted_idx]\r\n","\r\n","print(batch)\r\n","print(batch_lens)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[85, 14, 80, 34, 99, 20, 31, 65, 53, 86,  3, 58, 30,  4, 11,  6, 50, 71,\n","         74, 13],\n","        [58, 13, 40, 61, 88, 18, 92, 89,  8, 14, 61, 67, 49, 59, 45, 12, 47,  5,\n","          0,  0],\n","        [87, 32, 79, 65,  2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80,\n","          0,  0],\n","        [22,  5, 21, 84, 39,  6,  9, 84, 36, 59, 32, 30, 69, 70, 82, 56,  1,  0,\n","          0,  0],\n","        [70, 28, 30, 24, 76, 84, 92, 76, 77, 51,  7, 20, 82, 94, 57,  0,  0,  0,\n","          0,  0],\n","        [19, 83, 88, 22, 57, 40, 75, 82,  4, 46,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [93, 77, 16, 67, 46, 74, 24, 70,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [94, 21, 79, 24,  3, 86,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [80, 80, 33, 63, 34, 63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [62, 76, 79, 66, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0]])\n","tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mPRtdhHoUKhH"},"source":["### **LSTM 사용**"]},{"cell_type":"markdown","metadata":{"id":"l1FvfENCUqYN"},"source":["LSTM에선 cell state가 추가됩니다.  \r\n","Cell state의 shape는 hidden state의 그것과 동일합니다."]},{"cell_type":"code","metadata":{"id":"Q76VGoCCUrcQ"},"source":["embedding_size = 256\r\n","hidden_size = 512\r\n","num_layers = 1\r\n","num_dirs = 1\r\n","\r\n","embedding = nn.Embedding(vocab_size, embedding_size)\r\n","lstm = nn.LSTM(\r\n","    input_size=embedding_size,\r\n","    hidden_size=hidden_size,\r\n","    num_layers=num_layers,\r\n","    bidirectional=True if num_dirs > 1 else False\r\n",")\r\n","\r\n","h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)\r\n","c_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhS7qvIKWYYb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613457002153,"user_tz":-540,"elapsed":4601,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"e0236c5d-6d77-446e-ab0a-268eab168fb8"},"source":["# d_w: word embedding size\r\n","batch_emb = embedding(batch)  # (B, L, d_w)\r\n","\r\n","packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\r\n","\r\n","packed_outputs, (h_n, c_n) = lstm(packed_batch, (h_0, c_0))\r\n","print(packed_outputs)\r\n","print(packed_outputs[0].shape)\r\n","print(h_n.shape)\r\n","print(c_n.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PackedSequence(data=tensor([[ 0.0595, -0.0040,  0.0077,  ..., -0.0119,  0.1588, -0.1249],\n","        [ 0.0119, -0.0227,  0.0979,  ...,  0.1003, -0.1593, -0.1279],\n","        [-0.1457,  0.0142,  0.0047,  ...,  0.1214, -0.0040, -0.0921],\n","        ...,\n","        [-0.2004,  0.0955,  0.0751,  ..., -0.1047,  0.0018,  0.0140],\n","        [-0.0596, -0.0289, -0.2639,  ..., -0.0982, -0.0270, -0.0930],\n","        [-0.2460, -0.1123, -0.1709,  ..., -0.0871,  0.0401, -0.1330]],\n","       grad_fn=<CatBackward>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n","         1,  1]), sorted_indices=None, unsorted_indices=None)\n","torch.Size([123, 512])\n","torch.Size([1, 10, 512])\n","torch.Size([1, 10, 512])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ArOrgjHjZqAa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613457002153,"user_tz":-540,"elapsed":4599,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"c4e501ac-ff11-420a-ae41-c2b601d0e51f"},"source":["outputs, output_lens = pad_packed_sequence(packed_outputs)\r\n","print(outputs.shape)\r\n","print(output_lens)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([20, 10, 512])\n","tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"meuNwIIn-H-g"},"source":["### **GRU 사용**"]},{"cell_type":"markdown","metadata":{"id":"kMUysrtLihqt"},"source":["GRU는 cell state가 없어 RNN과 동일하게 사용 가능합니다.   \r\n","GRU를 이용하여 LM task를 수행해봅시다."]},{"cell_type":"code","metadata":{"id":"ZHw8PSf--lVg","executionInfo":{"status":"ok","timestamp":1613457441661,"user_tz":-540,"elapsed":672,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["gru = nn.GRU(\r\n","    input_size=embedding_size,\r\n","    hidden_size=hidden_size,\r\n","    num_layers=num_layers,\r\n","    bidirectional=True if num_dirs > 1 else False\r\n",")"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"GbMy2CkWzobD","executionInfo":{"status":"ok","timestamp":1613457442692,"user_tz":-540,"elapsed":706,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["output_layer = nn.Linear(hidden_size, vocab_size)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"YavlcFZywCBK","executionInfo":{"status":"ok","timestamp":1613457443423,"user_tz":-540,"elapsed":560,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["input_id = batch.transpose(0, 1)[0, :]  # (B)\r\n","hidden = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (1, B, d_h)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e1tFGyvo-uHb"},"source":["Teacher forcing 없이 이전에 얻은 결과를 다음 input으로 이용합니다.\r\n","- Teacher forcing : Language model의 RNN의 경우, output이 다음 rnn unit의 input이 되는데, 이때 첫 output은 학습이 덜된 만큼, 부정확한 output이 나오게 되며, 이 부정확한 결과값이 다음 결과값으로 다시 들어가게 되면 오류의 연쇄가 이루어지므로, 처음 몇 input은 forward 결과값이 아닌 맞는 글자 몇개를 넣어주는 것"]},{"cell_type":"code","metadata":{"id":"J6HRC3TAxtGa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613457002157,"user_tz":-540,"elapsed":4593,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"2c5819ce-c0b5-4225-c593-206a2e410f07"},"source":["for t in range(max_len):\r\n","  input_emb = embedding(input_id).unsqueeze(0)  # (1, B, d_w)\r\n","  output, hidden = gru(input_emb, hidden)  # output: (1, B, d_h), hidden: (1, B, d_h)\r\n","\r\n","  # V: vocab size\r\n","  output = output_layer(output)  # (1, B, V)\r\n","  probs, top_id = torch.max(output, dim=-1)  # probs: (1, B), top_id: (1, B)\r\n","\r\n","  print(\"*\" * 50)\r\n","  print(f\"Time step: {t}\")\r\n","  print(output.shape)\r\n","  print(probs.shape)\r\n","  print(top_id.shape)\r\n","\r\n","  input_id = top_id.squeeze(0)  # (B)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["**************************************************\n","Time step: 0\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 1\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 2\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 3\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 4\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 5\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 6\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 7\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 8\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 9\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 10\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 11\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 12\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 13\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 14\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 15\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 16\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 17\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 18\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 19\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WY3vh9Cm4KaH"},"source":["`max_len`만큼의 for 문을 돌면서 모든 결과물의 모양을 확인했지만 만약 종료 조건(예를 들어 문장의 끝을 나타내는 end token 등)이 되면 중간에 생성을 그만둘 수도 있습니다."]},{"cell_type":"markdown","metadata":{"id":"l07L_QncemE7"},"source":["### **양방향 및 여러 layer 사용**\r\n","- 표현력이나 역방향 오류 학습 등에 유리함"]},{"cell_type":"markdown","metadata":{"id":"lasjjz-teohw"},"source":["이번엔 양방향 + 2개 이상의 layer를 쓸 때 얻을 수 있는 결과에 대해 알아봅니다."]},{"cell_type":"code","metadata":{"id":"JEy00WX3ghsb"},"source":["num_layers = 2\r\n","num_dirs = 2\r\n","dropout=0.1\r\n","\r\n","gru = nn.GRU(\r\n","    input_size=embedding_size,\r\n","    hidden_size=hidden_size,\r\n","    num_layers=num_layers,\r\n","    dropout=dropout,\r\n","    bidirectional=True if num_dirs > 1 else False\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QX4LVL_Ag4kK"},"source":["Bidirectional이 되었고 layer의 개수가 $2$로 늘었기 때문에 hidden state의 shape도 `(4, B, d_h)`가 됩니다."]},{"cell_type":"code","metadata":{"id":"Q8aBk8yrfOHU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613457002159,"user_tz":-540,"elapsed":4590,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"726ee64b-1db2-4aec-9830-820fe8c67b8a"},"source":["# d_w: word embedding size, num_layers: layer의 개수, num_dirs: 방향의 개수\r\n","batch_emb = embedding(batch)  # (B, L, d_w)\r\n","h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h) = (4, B, d_h)\r\n","\r\n","packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\r\n","\r\n","packed_outputs, h_n = gru(packed_batch, h_0)\r\n","print(packed_outputs)\r\n","print(packed_outputs[0].shape)\r\n","print(h_n.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PackedSequence(data=tensor([[-0.0507, -0.0480, -0.0159,  ...,  0.2252, -0.0927,  0.0827],\n","        [ 0.0437, -0.0100, -0.0829,  ..., -0.0683,  0.0562,  0.1706],\n","        [ 0.0070,  0.0522, -0.0965,  ..., -0.3269,  0.0706,  0.0072],\n","        ...,\n","        [ 0.0294,  0.0397, -0.2067,  ..., -0.1246, -0.0613, -0.0025],\n","        [-0.0797, -0.0464, -0.1039,  ..., -0.1457,  0.0438, -0.0042],\n","        [-0.0339,  0.0147, -0.1073,  ..., -0.1251,  0.0784,  0.0458]],\n","       grad_fn=<CatBackward>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n","         1,  1]), sorted_indices=None, unsorted_indices=None)\n","torch.Size([123, 1024])\n","torch.Size([4, 10, 512])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VQdVtMcehndm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613457002160,"user_tz":-540,"elapsed":4586,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"96e31cb8-4a17-4d38-9b6f-f1ccfc413e85"},"source":["outputs, output_lens = pad_packed_sequence(packed_outputs)\r\n","\r\n","print(outputs.shape)  # (L, B, num_dirs*d_h) # 순방향 + 역방향이 더해져서 *2되서 들어감\r\n","print(output_lens)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([20, 10, 1024])\n","tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"byuggMjekUxS"},"source":["각각의 결과물의 shape는 다음과 같습니다.\r\n","\r\n","`outputs`: `(max_len, batch_size, num_dir * hidden_size)`  \r\n","`h_n`: `(num_layers*num_dirs, batch_size, hidden_size)`"]},{"cell_type":"code","metadata":{"id":"HaXhvyHjmFR3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613457002161,"user_tz":-540,"elapsed":4585,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"4d1a0d6e-cc09-45ee-db24-c7a06cf7dddf"},"source":["batch_size = h_n.shape[1]\r\n","print(h_n.view(num_layers, num_dirs, batch_size, hidden_size))\r\n","print(h_n.view(num_layers, num_dirs, batch_size, hidden_size).shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[[[-0.4698,  0.1134,  0.0114,  ...,  0.4740,  0.1314,  0.1918],\n","          [ 0.2275, -0.3115, -0.0690,  ..., -0.0710,  0.2036, -0.0498],\n","          [ 0.1226,  0.1501,  0.1331,  ...,  0.1928, -0.1684, -0.3177],\n","          ...,\n","          [ 0.1425, -0.2785, -0.2396,  ..., -0.0922, -0.2213,  0.0465],\n","          [-0.0170, -0.2781, -0.3475,  ..., -0.1992, -0.1689, -0.5524],\n","          [ 0.3580,  0.0931,  0.1165,  ..., -0.1966,  0.0253, -0.3083]],\n","\n","         [[ 0.2296, -0.1377,  0.3120,  ..., -0.4047, -0.2527,  0.3975],\n","          [-0.3439,  0.4143, -0.3206,  ..., -0.3364, -0.2994,  0.2221],\n","          [-0.0751,  0.0744,  0.2326,  ...,  0.1420,  0.0966, -0.0721],\n","          ...,\n","          [-0.1620,  0.0401,  0.2431,  ..., -0.1816, -0.3418, -0.2659],\n","          [ 0.1814, -0.1343,  0.1242,  ...,  0.0192,  0.1938,  0.5862],\n","          [ 0.0556, -0.2684, -0.1088,  ..., -0.0943,  0.1075,  0.1678]]],\n","\n","\n","        [[[-0.0339,  0.0147, -0.1073,  ..., -0.1782, -0.0612, -0.1116],\n","          [-0.0950,  0.1070,  0.1114,  ..., -0.1317,  0.2098, -0.2578],\n","          [ 0.0294,  0.0397, -0.2067,  ..., -0.0909, -0.0032, -0.0128],\n","          ...,\n","          [ 0.1734, -0.0728, -0.1163,  ..., -0.0434, -0.2051, -0.0524],\n","          [-0.0629,  0.0339, -0.0266,  ..., -0.3598, -0.0746,  0.0883],\n","          [ 0.2586, -0.1497,  0.0096,  ..., -0.0725, -0.3104, -0.2171]],\n","\n","         [[ 0.1454,  0.0314, -0.2348,  ...,  0.2252, -0.0927,  0.0827],\n","          [ 0.0534, -0.3263, -0.1753,  ..., -0.0683,  0.0562,  0.1706],\n","          [ 0.1059, -0.0157, -0.1319,  ..., -0.3269,  0.0706,  0.0072],\n","          ...,\n","          [-0.0629, -0.1158,  0.1018,  ...,  0.0322, -0.2358, -0.0215],\n","          [-0.1186, -0.2267, -0.0986,  ..., -0.2254, -0.0692,  0.1623],\n","          [ 0.0627, -0.2501, -0.1652,  ..., -0.0735, -0.0156, -0.2155]]]],\n","       grad_fn=<ViewBackward>)\n","torch.Size([2, 2, 10, 512])\n"],"name":"stdout"}]}]}