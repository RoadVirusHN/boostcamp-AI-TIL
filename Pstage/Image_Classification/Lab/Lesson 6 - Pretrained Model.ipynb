{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minute-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-wound",
   "metadata": {},
   "source": [
    "## Lesson 6 - Pretrained Model\n",
    " - 이번 실습 자료에서는 강의시간에 다루었던 torchvision 을 사용하여 pretrained 모델을 사용하는 방법에 대해 실습하겠습니다.\n",
    " - torchvision 의 pretrained model 리스트는 다음과 같습니다\n",
    " \n",
    " [List of torchvision models](https://github.com/pytorch/vision/blob/master/torchvision/models/__init__.py#L1-L14)\n",
    "```\n",
    "from .alexnet import *\n",
    "from .resnet import *\n",
    "from .vgg import *\n",
    "from .squeezenet import *\n",
    "from .inception import *\n",
    "from .densenet import *\n",
    "from .googlenet import *\n",
    "from .mobilenet import *\n",
    "from .mnasnet import *\n",
    "from .shufflenetv2 import *\n",
    "from . import segmentation\n",
    "from . import detection\n",
    "from . import video\n",
    "from . import quantization\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-antigua",
   "metadata": {},
   "source": [
    "#### 가장 기본이라고 할 수 있는 Alextnet 모델 아키텍쳐를 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "future-enhancement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import alexnet\n",
    "model = alexnet()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-finding",
   "metadata": {},
   "source": [
    "#### Alexnet 의 pretrained 버전 또한 쉽게 불러올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "illegal-harmony",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /opt/ml/.cache/torch/hub/checkpoints/alexnet-owt-4df8aa71.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8a31fe69d449efb67d2dcb08d3f81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = alexnet(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-vector",
   "metadata": {},
   "source": [
    "#### torchvision 에서 해당 모델을 어떤 식으로 구현하였는지 직접 확인해보면 매우 도움이 많으 됩니다.\n",
    "Example:\n",
    "[source code](https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py#L15-L50)\n",
    "```\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-system",
   "metadata": {},
   "source": [
    "#### 다른 모델들( e.g. vgg19, resnet18) 도 같은 방법으로 손 쉽게 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compatible-vulnerability",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /opt/ml/.cache/torch/hub/checkpoints/vgg19_bn-c79401a0.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd97284b3da4e45a34d089d21b69002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=574769405.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (51): ReLU(inplace=True)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import vgg19_bn\n",
    "model = vgg19_bn(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-engine",
   "metadata": {},
   "source": [
    "#### Pretrained 모델을 내 태스크에 맞게 어떻게 사용할 수 있나요?\n",
    " - Trochvision 모델들은 보통 feature-extraction 파트, task-specific 파트로 크게 두 가지로 구성되어 있습니다.\n",
    " - Task specific 파트는 모델의 태스크(이미지 분류, 객체 인식 등) 에 따라 모두 다릅니다.\n",
    " - 심지어 같은 이미지 분류 안에서도, 어떤 데이터셋으로 pretrain 하였느냐에 따라 다를 수 있습니다.\n",
    " - 따라서, 우리도 우리 테스크에 맞게 task specific 파트는 새로 정의하여 사용하여야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-breast",
   "metadata": {},
   "source": [
    " - 주로 이미지넷 데이터셋을 사용하여 pretrain 을 하기에 output_dim=1000 인 경우가 많습니다.\n",
    " - 따라서 우리 태스크의 클래스 갯수(18)에 맞게 재정의하여 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accessible-plane",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (51): ReLU(inplace=True)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 18\n",
    "model = vgg19_bn(pretrained=True)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(512 * 7 * 7, 4096),\n",
    "    nn.ReLU(True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, num_classes),\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-sector",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-pharmaceutical",
   "metadata": {},
   "source": [
    "#### Weight Freeze\n",
    " - Weight freeze 란 해당 모듈의 graident 는 역전파 하지 않아 학습을 하지 않는다는 의미입니다.\n",
    " - 예를 들어, 우리가 하려는 태스크가 pretrain 한 태스크와 매우 유사하다면, feature 파트는 freeze 하여 학습하지 않고 새로 정의한 task specific 파트만 학습하는 것이 좋은 방법일 수 있습니다.\n",
    " - weight freeze 는 `requires_grad` 를 사용하여 쉽게 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coordinate-aggregate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param features.0.weight    required gradient? -> False\n",
      "param features.0.bias      required gradient? -> False\n",
      "param features.1.weight    required gradient? -> False\n",
      "param features.1.bias      required gradient? -> False\n",
      "param features.3.weight    required gradient? -> False\n",
      "param features.3.bias      required gradient? -> False\n",
      "param features.4.weight    required gradient? -> False\n",
      "param features.4.bias      required gradient? -> False\n",
      "param features.7.weight    required gradient? -> False\n",
      "param features.7.bias      required gradient? -> False\n",
      "param features.8.weight    required gradient? -> False\n",
      "param features.8.bias      required gradient? -> False\n",
      "param features.10.weight   required gradient? -> False\n",
      "param features.10.bias     required gradient? -> False\n",
      "param features.11.weight   required gradient? -> False\n",
      "param features.11.bias     required gradient? -> False\n",
      "param features.14.weight   required gradient? -> False\n",
      "param features.14.bias     required gradient? -> False\n",
      "param features.15.weight   required gradient? -> False\n",
      "param features.15.bias     required gradient? -> False\n",
      "param features.17.weight   required gradient? -> False\n",
      "param features.17.bias     required gradient? -> False\n",
      "param features.18.weight   required gradient? -> False\n",
      "param features.18.bias     required gradient? -> False\n",
      "param features.20.weight   required gradient? -> False\n",
      "param features.20.bias     required gradient? -> False\n",
      "param features.21.weight   required gradient? -> False\n",
      "param features.21.bias     required gradient? -> False\n",
      "param features.23.weight   required gradient? -> False\n",
      "param features.23.bias     required gradient? -> False\n",
      "param features.24.weight   required gradient? -> False\n",
      "param features.24.bias     required gradient? -> False\n",
      "param features.27.weight   required gradient? -> False\n",
      "param features.27.bias     required gradient? -> False\n",
      "param features.28.weight   required gradient? -> False\n",
      "param features.28.bias     required gradient? -> False\n",
      "param features.30.weight   required gradient? -> False\n",
      "param features.30.bias     required gradient? -> False\n",
      "param features.31.weight   required gradient? -> False\n",
      "param features.31.bias     required gradient? -> False\n",
      "param features.33.weight   required gradient? -> False\n",
      "param features.33.bias     required gradient? -> False\n",
      "param features.34.weight   required gradient? -> False\n",
      "param features.34.bias     required gradient? -> False\n",
      "param features.36.weight   required gradient? -> False\n",
      "param features.36.bias     required gradient? -> False\n",
      "param features.37.weight   required gradient? -> False\n",
      "param features.37.bias     required gradient? -> False\n",
      "param features.40.weight   required gradient? -> False\n",
      "param features.40.bias     required gradient? -> False\n",
      "param features.41.weight   required gradient? -> False\n",
      "param features.41.bias     required gradient? -> False\n",
      "param features.43.weight   required gradient? -> False\n",
      "param features.43.bias     required gradient? -> False\n",
      "param features.44.weight   required gradient? -> False\n",
      "param features.44.bias     required gradient? -> False\n",
      "param features.46.weight   required gradient? -> False\n",
      "param features.46.bias     required gradient? -> False\n",
      "param features.47.weight   required gradient? -> False\n",
      "param features.47.bias     required gradient? -> False\n",
      "param features.49.weight   required gradient? -> False\n",
      "param features.49.bias     required gradient? -> False\n",
      "param features.50.weight   required gradient? -> False\n",
      "param features.50.bias     required gradient? -> False\n",
      "param classifier.0.weight  required gradient? -> True\n",
      "param classifier.0.bias    required gradient? -> True\n",
      "param classifier.3.weight  required gradient? -> True\n",
      "param classifier.3.bias    required gradient? -> True\n",
      "param classifier.6.weight  required gradient? -> True\n",
      "param classifier.6.bias    required gradient? -> True\n"
     ]
    }
   ],
   "source": [
    "# Freeze only feauture parts\n",
    "model.features.requires_grad_(False)\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"param {param:20} required gradient? -> {weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-still",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "streaming-cotton",
   "metadata": {},
   "source": [
    "#### Weight initialization \n",
    " - weight 초기화는 종종 모델의 성능에 critical 한 영향을 줍니다.\n",
    " - 하지만 만약 pretrained 모델을 사용한다면 pretrained 부분은 초기화를 하지 말고, 재정의한 task specific 파트만 초기화하여야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lucky-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def initialize_weights(model):\n",
    "    \"\"\"\n",
    "    Initialize all weights using xavier uniform. \n",
    "    For more weight initialization methods, check https://pytorch.org/docs/stable/nn.init.html\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-class",
   "metadata": {},
   "source": [
    "#### pretrained 모델을 가져와 가장 앞단 layer 의 weight 분포를 봐봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "veterinary-ireland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00e+00, 0.00e+00, 1.00e+01, 3.50e+01, 1.58e+02, 1.47e+03,\n",
       "        4.00e+01, 1.30e+01, 0.00e+00, 1.00e+00]),\n",
       " array([-1.644177  , -1.3200787 , -0.99598044, -0.67188215, -0.3477839 ,\n",
       "        -0.02368563,  0.30041263,  0.6245109 ,  0.9486092 ,  1.2727075 ,\n",
       "         1.5968057 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAR00lEQVR4nO3dfYzc113v8ffnxiSlhVs78ZIG28UpWIWAQI1WaaAIVTWkSYrqINoqFSJuMTIVKU9FKi5IRCpCtPde3UAEBJnG1JGqtCU8xEBKMEmrCgmHbErz3JJtSGtbTrw0qaFUtAS+/DHHMHV2vQ+zO2P3vF/SaM7vnDPz+85o9JnfnvnNbKoKSVIf/tekC5AkjY+hL0kdMfQlqSOGviR1xNCXpI6sm3QBp7Nx48baunXrpMuQpLPK/fff/09VNTXf2Bkd+lu3bmVmZmbSZUjSWSXJZxcac3lHkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6ckZ/I1c6k23d8xcT2e+T73ndRParrw0e6UtSRwx9SeqIoS9JHTH0Jakjhr4kdWTR0E+yL8nxJA/PM/aLSSrJxradJDclmU3yYJJLh+buTPJ4u+xc3YchSVqKpRzpvx+48tTOJFuAK4DPDXVfBWxrl93AzW3u+cANwCuBy4AbkmwYpXBJ0vItGvpV9XHgmXmGbgTeCdRQ3w7g1ho4BKxPchHwWuBgVT1TVc8CB5nnjUSStLZWtKafZAdwtKoeOGVoE3B4aPtI61uoX5I0Rsv+Rm6SFwK/zGBpZ9Ul2c1gaYiXvvSla7ELSerWSo70vxW4GHggyZPAZuATSV4CHAW2DM3d3PoW6n+eqtpbVdNVNT01Ne8/c5ckrdCyQ7+qHqqqb6qqrVW1lcFSzaVV9RRwALiuncVzOXCiqo4BdwFXJNnQPsC9ovVJksZoKads3gb8LfDyJEeS7DrN9DuBJ4BZ4PeBnwaoqmeAXwPua5d3tz5J0hgtuqZfVW9eZHzrULuA6xeYtw/Yt8z6JEmryG/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4uGfpJ9SY4neXio7/8m+VSSB5P8SZL1Q2PvSjKb5NNJXjvUf2Xrm02yZ/UfiiRpMUs50n8/cOUpfQeB76qq7wb+AXgXQJJLgGuB72y3+d0k5yQ5B/gd4CrgEuDNba4kaYwWDf2q+jjwzCl9f1VVz7XNQ8Dm1t4BfLCqvlxV/wjMApe1y2xVPVFVXwE+2OZKksZoNdb0fwL4SGtvAg4PjR1pfQv1P0+S3UlmkszMzc2tQnmSpJNGCv0kvwI8B3xgdcqBqtpbVdNVNT01NbVadytJAtat9IZJ3gL8MLC9qqp1HwW2DE3b3Po4Tb8kaUxWdKSf5ErgncDrq+pLQ0MHgGuTnJfkYmAb8HfAfcC2JBcnOZfBh70HRitdkrRcix7pJ7kNeDWwMckR4AYGZ+ucBxxMAnCoqt5WVY8k+TDwKINln+ur6j/a/bwduAs4B9hXVY+sweORJJ3GoqFfVW+ep/uW08z/deDX5+m/E7hzWdVJklaV38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOrJo6CfZl+R4koeH+s5PcjDJ4+16Q+tPkpuSzCZ5MMmlQ7fZ2eY/nmTn2jwcSdLpLOVI//3Alaf07QHurqptwN1tG+AqYFu77AZuhsGbBHAD8ErgMuCGk28UkqTxWTT0q+rjwDOndO8A9rf2fuCaof5ba+AQsD7JRcBrgYNV9UxVPQsc5PlvJJKkNbbSNf0Lq+pYaz8FXNjam4DDQ/OOtL6F+p8nye4kM0lm5ubmVlieJGk+I3+QW1UF1CrUcvL+9lbVdFVNT01NrdbdSpJYeeg/3ZZtaNfHW/9RYMvQvM2tb6F+SdIYrTT0DwAnz8DZCdwx1H9dO4vncuBEWwa6C7giyYb2Ae4VrU+SNEbrFpuQ5Dbg1cDGJEcYnIXzHuDDSXYBnwXe1KbfCVwNzAJfAt4KUFXPJPk14L42791VdeqHw5KkNbZo6FfVmxcY2j7P3AKuX+B+9gH7llWdJGlV+Y1cSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSMjhX6SX0jySJKHk9yW5AVJLk5yb5LZJB9Kcm6be17bnm3jW1fjAUiSlm7FoZ9kE/CzwHRVfRdwDnAt8F7gxqr6NuBZYFe7yS7g2dZ/Y5snSRqjUZd31gFfn2Qd8ELgGPAa4PY2vh+4prV3tG3a+PYkGXH/kqRlWHHoV9VR4P8Bn2MQ9ieA+4EvVNVzbdoRYFNrbwIOt9s+1+ZfcOr9JtmdZCbJzNzc3ErLkyTNY5TlnQ0Mjt4vBr4ZeBFw5agFVdXeqpququmpqalR706SNGSU5Z0fBP6xquaq6t+BPwZeBaxvyz0Am4GjrX0U2ALQxl8MfH6E/UuSlmmU0P8ccHmSF7a1+e3Ao8BHgTe0OTuBO1r7QNumjd9TVTXC/iVJyzTKmv69DD6Q/QTwULuvvcAvAe9IMstgzf6WdpNbgAta/zuAPSPULUlagXWLT1lYVd0A3HBK9xPAZfPM/TfgjaPsT5I0Gr+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVkpNBPsj7J7Uk+leSxJN+b5PwkB5M83q43tLlJclOS2SQPJrl0dR6CJGmpRj3S/y3gL6vq24HvAR4D9gB3V9U24O62DXAVsK1ddgM3j7hvSdIyrTj0k7wY+AHgFoCq+kpVfQHYAexv0/YD17T2DuDWGjgErE9y0YorlyQt2yhH+hcDc8AfJPn7JO9L8iLgwqo61uY8BVzY2puAw0O3P9L6vkqS3UlmkszMzc2NUJ4k6VSjhP464FLg5qp6BfCv/M9SDgBVVUAt506ram9VTVfV9NTU1AjlSZJONUroHwGOVNW9bft2Bm8CT59ctmnXx9v4UWDL0O03tz5J0pisOPSr6ingcJKXt67twKPAAWBn69sJ3NHaB4Dr2lk8lwMnhpaBJEljsG7E2/8M8IEk5wJPAG9l8Eby4SS7gM8Cb2pz7wSuBmaBL7W5kqQxGin0q+qTwPQ8Q9vnmVvA9aPsT5I0Gr+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVk5NBPck6Sv0/y52374iT3JplN8qH2T9NJcl7bnm3jW0fdtyRpeVbjSP/ngMeGtt8L3FhV3wY8C+xq/buAZ1v/jW2eJGmMRgr9JJuB1wHva9sBXgPc3qbsB65p7R1tmza+vc2XJI3JqEf6vwm8E/jPtn0B8IWqeq5tHwE2tfYm4DBAGz/R5n+VJLuTzCSZmZubG7E8SdKwFYd+kh8GjlfV/atYD1W1t6qmq2p6ampqNe9akrq3boTbvgp4fZKrgRcA/xv4LWB9knXtaH4zcLTNPwpsAY4kWQe8GPj8CPuXJC3Tio/0q+pdVbW5qrYC1wL3VNWPAR8F3tCm7QTuaO0DbZs2fk9V1Ur3L0lavrU4T/+XgHckmWWwZn9L678FuKD1vwPYswb7liSdxijLO/+tqj4GfKy1nwAum2fOvwFvXI39SZJWxm/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR1Zcegn2ZLko0keTfJIkp9r/ecnOZjk8Xa9ofUnyU1JZpM8mOTS1XoQkqSlGeVI/zngF6vqEuBy4PoklwB7gLurahtwd9sGuArY1i67gZtH2LckaQVWHPpVdayqPtHa/wI8BmwCdgD727T9wDWtvQO4tQYOAeuTXLTiyiVJy7Yqa/pJtgKvAO4FLqyqY23oKeDC1t4EHB662ZHWJ0kak5FDP8k3AH8E/HxV/fPwWFUVUMu8v91JZpLMzM3NjVqeJGnISKGf5OsYBP4HquqPW/fTJ5dt2vXx1n8U2DJ0882t76tU1d6qmq6q6ampqVHKkySdYpSzdwLcAjxWVf9/aOgAsLO1dwJ3DPVf187iuRw4MbQMJEkag3Uj3PZVwI8DDyX5ZOv7ZeA9wIeT7AI+C7ypjd0JXA3MAl8C3jrCviVJK7Di0K+qvwGywPD2eeYXcP1K9ydJGp3fyJWkjoyyvCNN3NY9fzHpEqSzikf6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTf05fOMpP8HwJPvud1E9u3Voehr1XhPzORzg4u70hSR8Ye+kmuTPLpJLNJ9ox7/5LUs7Eu7yQ5B/gd4IeAI8B9SQ5U1aPjrONrmcssWkuTen35WcLqGfeR/mXAbFU9UVVfAT4I7BhzDZLUrXF/kLsJODy0fQR45fCEJLuB3W3zi0k+PabaTtoI/NOY97larH0yrH2N5b3zdp8VtS9grWv/loUGzrizd6pqL7B3UvtPMlNV05Pa/yisfTKsfTKsfWXGvbxzFNgytL259UmSxmDcoX8fsC3JxUnOBa4FDoy5Bknq1liXd6rquSRvB+4CzgH2VdUj46xhCSa2tLQKrH0yrH0yrH0FUlWT2rckacz8Rq4kdcTQl6SOdB/6Sd6Y5JEk/5lkwVOokjyZ5KEkn0wyM84aF7KM2s+4n75Icn6Sg0keb9cbFpj3H+05/2SSiX7ov9jzmOS8JB9q4/cm2Tr+Kue3hNrfkmRu6Ln+yUnUeaok+5IcT/LwAuNJclN7XA8muXTcNS5kCbW/OsmJoef8V8dSWFV1fQG+A3g58DFg+jTzngQ2Trre5dbO4APzzwAvA84FHgAuOQNq/z/AntbeA7x3gXlfnHStS30egZ8Gfq+1rwU+NOm6l1H7W4DfnnSt89T+A8ClwMMLjF8NfAQIcDlw76RrXkbtrwb+fNx1dX+kX1WPVdW4v/W7KpZY+5n60xc7gP2tvR+4ZoK1LMVSnsfhx3Q7sD1JxljjQs7U18CiqurjwDOnmbIDuLUGDgHrk1w0nupObwm1T0T3ob8MBfxVkvvbT0WcLeb76YtNE6pl2IVVday1nwIuXGDeC5LMJDmUZJJvDEt5Hv97TlU9B5wALhhLdae31NfAj7YlktuTbJln/Ex0pr6+l+p7kzyQ5CNJvnMcOzzjfoZhLST5a+Al8wz9SlXdscS7+f6qOprkm4CDST7V3snX1CrVPhGnq314o6oqyULnDn9Le95fBtyT5KGq+sxq1yr+DLitqr6c5KcY/MXymgnX9LXuEwxe319McjXwp8C2td5pF6FfVT+4CvdxtF0fT/InDP5kXvPQX4XaJ/bTF6erPcnTSS6qqmPtz/HjC9zHyef9iSQfA17BYH163JbyPJ6ccyTJOuDFwOfHU95pLVp7VQ3X+T4Gn7mcDc7an3apqn8eat+Z5HeTbKyqNf0ROZd3liDJi5J848k2cAUw7yfyZ6Az9acvDgA7W3sn8Ly/WpJsSHJea28EXgVM6n8vLOV5HH5MbwDuqfaJ3YQtWvsp6+CvBx4bY32jOABc187iuRw4MbRseEZL8pKTn/kkuYxBHq/9QcKkP+Ge9AX4EQbrgF8Gngbuav3fDNzZ2i9jcMbDA8AjDJZWzora2/bVwD8wOEI+U2q/ALgbeBz4a+D81j8NvK+1vw94qD3vDwG7Jlzz855H4N3A61v7BcAfArPA3wEvm/TzvIzaf6O9th8APgp8+6RrbnXdBhwD/r291ncBbwPe1sbD4B8zfaa9RhY8A+8MrP3tQ8/5IeD7xlGXP8MgSR1xeUeSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI78F3ziWQ9TiQOmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = vgg19_bn(pretrained=True)\n",
    "\n",
    "# Before initialize weights\n",
    "plt.hist(model.features[0].weight.detach().numpy().reshape(-1))  # weight distribution for first conv weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-engineer",
   "metadata": {},
   "source": [
    "#### weight 초기화 후 분포를 봐 봅시다\n",
    " - `xavier_uniform` 으로 초기화하여 웨이트들이 uniform 한 분포를 가지게 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acquired-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([167., 186., 159., 160., 166., 195., 171., 187., 161., 176.]),\n",
       " array([-9.9732459e-02, -7.9805337e-02, -5.9878223e-02, -3.9951101e-02,\n",
       "        -2.0023983e-02, -9.6864998e-05,  1.9830253e-02,  3.9757371e-02,\n",
       "         5.9684493e-02,  7.9611607e-02,  9.9538729e-02], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = vgg19_bn(pretrained=True)\n",
    "\n",
    "# Initalize all weights\n",
    "initialize_weights(model.features)\n",
    "\n",
    "# After initialize weights\n",
    "plt.hist(model.features[0].weight.detach().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-optimum",
   "metadata": {},
   "source": [
    "#### task specific 한 부분만 초기화하엿습니다\n",
    " - feature extraction 파트는 초기화가 되지 않은 것은 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "political-packaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00e+00, 0.00e+00, 1.00e+01, 3.50e+01, 1.58e+02, 1.47e+03,\n",
       "        4.00e+01, 1.30e+01, 0.00e+00, 1.00e+00]),\n",
       " array([-1.644177  , -1.3200787 , -0.99598044, -0.67188215, -0.3477839 ,\n",
       "        -0.02368563,  0.30041263,  0.6245109 ,  0.9486092 ,  1.2727075 ,\n",
       "         1.5968057 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = vgg19_bn(pretrained=True)\n",
    "\n",
    "# Initialize only classifier part\n",
    "initialize_weights(model.classifier)\n",
    "\n",
    "# After initialize weights\n",
    "plt.hist(model.features[0].weight.detach().numpy().reshape(-1))  # weight distribution for first conv weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-content",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "structured-irrigation",
   "metadata": {},
   "source": [
    "## Appendix (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-cosmetic",
   "metadata": {},
   "source": [
    "### SOTA (State Of The Art)  모델을 리서치 하는 방법\n",
    "- timm\n",
    "- paper with code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-projection",
   "metadata": {},
   "source": [
    "## timm (pyTorch IMage Models)\n",
    "\n",
    "PyTorch Image Models (timm) is a collection of image models, layers, utilities, optimizers, schedulers, data-loaders / augmentations, and reference training / validation scripts that aim to pull together a wide variety of SOTA models with ability to reproduce ImageNet training results.\n",
    "\n",
    "#### References\n",
    "https://github.com/rwightman/pytorch-image-models#introduction\n",
    "\n",
    "https://fastai.github.io/timmdocs/\n",
    "\n",
    "https://rwightman.github.io/pytorch-image-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "independent-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.4.5-py3-none-any.whl (287 kB)\n",
      "\u001b[K     |████████████████████████████████| 287 kB 562 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.18.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (7.2.0)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-management",
   "metadata": {},
   "source": [
    "#### Timm 을 사용하여 pretrained 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proof-environment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mobilenetv3_large_100_ra-f55367f5.pth\" to /opt/ml/.cache/torch/hub/checkpoints/mobilenetv3_large_100_ra-f55367f5.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (conv_stem): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): HardSwishMe()\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv_pwl): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "        (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "        (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "        (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "        (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "        (bn2): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (conv_pwl): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "        (bn2): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "        (bn2): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=False)\n",
       "  (conv_head): Conv2d(960, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (act2): HardSwishMe()\n",
       "  (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "m = timm.create_model('mobilenetv3_large_100', pretrained=True)\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-canyon",
   "metadata": {},
   "source": [
    "#### Timm 에서 사용가능한 pretrained 모델 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "quiet-trunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnext50',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b2a',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b3a',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_lite0',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'fbnetc_100',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mnasnet_100',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_rw',\n",
      " 'nasnetalarge',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_resnet50',\n",
      " 'nfnet_l0c',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50d',\n",
      " 'resnet101d',\n",
      " 'resnet152d',\n",
      " 'resnet200d',\n",
      " 'resnetblur50',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'semnasnet_100',\n",
      " 'seresnet50',\n",
      " 'seresnet152d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext50_32x4d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_in21k',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch32_224_in21k',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_resnet50_224_in21k',\n",
      " 'vit_base_resnet50_384',\n",
      " 'vit_deit_base_distilled_patch16_224',\n",
      " 'vit_deit_base_distilled_patch16_384',\n",
      " 'vit_deit_base_patch16_224',\n",
      " 'vit_deit_base_patch16_384',\n",
      " 'vit_deit_small_distilled_patch16_224',\n",
      " 'vit_deit_small_patch16_224',\n",
      " 'vit_deit_tiny_distilled_patch16_224',\n",
      " 'vit_deit_tiny_patch16_224',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_224_in21k',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_224_in21k',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-chemistry",
   "metadata": {},
   "source": [
    "#### 다음과 같은 방법을 통해서 원하는 모델을 찾는 것도 가능합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pretty-retirement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cspresnet50',\n",
      " 'cspresnet50d',\n",
      " 'cspresnet50w',\n",
      " 'cspresnext50',\n",
      " 'cspresnext50_iabn',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet200d',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'ecaresnext26t_32x4d',\n",
      " 'ecaresnext50t_32x4d',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'nf_ecaresnet26',\n",
      " 'nf_ecaresnet50',\n",
      " 'nf_ecaresnet101',\n",
      " 'nf_resnet26',\n",
      " 'nf_resnet50',\n",
      " 'nf_resnet101',\n",
      " 'nf_seresnet26',\n",
      " 'nf_seresnet50',\n",
      " 'nf_seresnet101',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50d',\n",
      " 'resnet101',\n",
      " 'resnet101d',\n",
      " 'resnet152',\n",
      " 'resnet152d',\n",
      " 'resnet200',\n",
      " 'resnet200d',\n",
      " 'resnetblur18',\n",
      " 'resnetblur50',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'resnext101_64x4d',\n",
      " 'seresnet18',\n",
      " 'seresnet34',\n",
      " 'seresnet50',\n",
      " 'seresnet50t',\n",
      " 'seresnet101',\n",
      " 'seresnet152',\n",
      " 'seresnet152d',\n",
      " 'seresnet200d',\n",
      " 'seresnet269d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext26tn_32x4d',\n",
      " 'seresnext50_32x4d',\n",
      " 'seresnext101_32x4d',\n",
      " 'seresnext101_32x8d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnet50',\n",
      " 'skresnet50d',\n",
      " 'skresnext50_32x4d',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'vit_base_resnet26d_224',\n",
      " 'vit_base_resnet50_224_in21k',\n",
      " 'vit_base_resnet50_384',\n",
      " 'vit_base_resnet50d_224',\n",
      " 'vit_small_resnet26d_224',\n",
      " 'vit_small_resnet50d_s3_224',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models('*resne*t*')\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-survey",
   "metadata": {},
   "source": [
    "## Paper with code\n",
    " - https://paperswithcode.com/task/image-classification\n",
    " - 다양한 태스크와 데이터셋에 대한 다양한 모델들의 성능을 벤치마킹해주는 웹서비스입니다.\n",
    " - 해당 서비스를 통해 각 모델들의 성능 비교뿐 아니라 논문과 구현 코드로 forwarding 도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-governor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
