{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7_multi_head_attention.ipynb의 사본","provenance":[{"file_id":"1Yp0oRPYUX7-9XISzhkUBd-18UiE7nsr_","timestamp":1613765178610}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9KsBGZpKkWki"},"source":["##**7. Multi-head Attention**\r\n","1. Multi-head attention 및 self-attention 구현.\r\n","2. 각 과정에서 일어나는 연산과 input/output 형태 이해."]},{"cell_type":"markdown","metadata":{"id":"8qRU5DFY2OM8"},"source":["### **필요 패키지 import**"]},{"cell_type":"code","metadata":{"id":"lDtMioSQQ1bB","executionInfo":{"status":"ok","timestamp":1613799445647,"user_tz":-540,"elapsed":907,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["from torch import nn\r\n","from torch.nn import functional as F\r\n","from tqdm import tqdm\r\n","\r\n","import torch\r\n","import math"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBiZObgRep_Q"},"source":["### **데이터 전처리**"]},{"cell_type":"code","metadata":{"id":"e9ULZIqTenSc","executionInfo":{"status":"ok","timestamp":1613799445648,"user_tz":-540,"elapsed":901,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["pad_id = 0\r\n","vocab_size = 100\r\n","\r\n","data = [\r\n","  [62, 13, 47, 39, 78, 33, 56, 13, 39, 29, 44, 86, 71, 36, 18, 75],\r\n","  [60, 96, 51, 32, 90],\r\n","  [35, 45, 48, 65, 91, 99, 92, 10, 3, 21, 54],\r\n","  [75, 51],\r\n","  [66, 88, 98, 47],\r\n","  [21, 39, 10, 64, 21],\r\n","  [98],\r\n","  [77, 65, 51, 77, 19, 15, 35, 19, 23, 97, 50, 46, 53, 42, 45, 91, 66, 3, 43, 10],\r\n","  [70, 64, 98, 25, 99, 53, 4, 13, 69, 62, 66, 76, 15, 75, 45, 34],\r\n","  [20, 64, 81, 35, 76, 85, 1, 62, 8, 45, 99, 77, 19, 43]\r\n","]"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Hx3mcivgMyH","executionInfo":{"status":"ok","timestamp":1613799446042,"user_tz":-540,"elapsed":1291,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["def padding(data):\r\n","  max_len = len(max(data, key=len))\r\n","  print(f\"Maximum sequence length: {max_len}\")\r\n","\r\n","  for i, seq in enumerate(tqdm(data)):\r\n","    if len(seq) < max_len:\r\n","      data[i] = seq + [pad_id] * (max_len - len(seq))\r\n","\r\n","  return data, max_len"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3e8FiNvgX60","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613799446049,"user_tz":-540,"elapsed":1291,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"a67842aa-1f29-4662-b739-844af806592a"},"source":["data, max_len = padding(data)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["100%|██████████| 10/10 [00:00<00:00, 62883.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["Maximum sequence length: 20\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hwPSIWYugaN0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613799446050,"user_tz":-540,"elapsed":1286,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"dda4bd28-d0c0-4272-a8e4-2792324e5333"},"source":["data"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[62, 13, 47, 39, 78, 33, 56, 13, 39, 29, 44, 86, 71, 36, 18, 75, 0, 0, 0, 0],\n"," [60, 96, 51, 32, 90, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [35, 45, 48, 65, 91, 99, 92, 10, 3, 21, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [75, 51, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [66, 88, 98, 47, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [21, 39, 10, 64, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [98, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," [77,\n","  65,\n","  51,\n","  77,\n","  19,\n","  15,\n","  35,\n","  19,\n","  23,\n","  97,\n","  50,\n","  46,\n","  53,\n","  42,\n","  45,\n","  91,\n","  66,\n","  3,\n","  43,\n","  10],\n"," [70, 64, 98, 25, 99, 53, 4, 13, 69, 62, 66, 76, 15, 75, 45, 34, 0, 0, 0, 0],\n"," [20, 64, 81, 35, 76, 85, 1, 62, 8, 45, 99, 77, 19, 43, 0, 0, 0, 0, 0, 0]]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"rwqjACx8iidc"},"source":["### **Hyperparameter 세팅 및 embedding**"]},{"cell_type":"code","metadata":{"id":"p-Ngp2nWimS8","executionInfo":{"status":"ok","timestamp":1613799446050,"user_tz":-540,"elapsed":1280,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["d_model = 512  # model의 hidden size\r\n","num_heads = 8  # head의 개수, d_model%num_heads == 0이어야 한다"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJMi2Xsni5uq","executionInfo":{"status":"ok","timestamp":1613799446051,"user_tz":-540,"elapsed":1276,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["embedding = nn.Embedding(vocab_size, d_model)\r\n","\r\n","# B: batch size, L: maximum sequence length\r\n","batch = torch.LongTensor(data)  # (B, L)\r\n","batch_emb = embedding(batch)  # (B, L, d_model)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"3tLCUQwojcUb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613799446051,"user_tz":-540,"elapsed":1269,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"57081200-433a-46eb-86ff-ddd4dc743b74"},"source":["print(batch_emb)\r\n","print(batch_emb.shape)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["tensor([[[ 1.7307, -1.4483, -0.0433,  ..., -1.8369, -0.7755, -0.6538],\n","         [ 1.2350, -0.2202,  0.1944,  ..., -0.8821, -1.9208, -0.9424],\n","         [ 1.1804, -0.4475,  1.6954,  ...,  1.6695,  0.0476,  2.2247],\n","         ...,\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114],\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114],\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114]],\n","\n","        [[-1.0603, -0.0627, -0.1550,  ..., -0.4284,  0.7544, -1.2059],\n","         [ 0.9366,  1.0761, -0.4529,  ...,  1.7042,  0.3171, -0.2775],\n","         [-0.1113,  1.2346,  1.0658,  ...,  0.8423,  0.6119,  2.4125],\n","         ...,\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114],\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114],\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114]],\n","\n","        [[-0.6782, -0.4049,  0.1398,  ..., -0.2391, -1.0342,  0.5864],\n","         [-0.2481, -0.0813, -0.9470,  ..., -1.0726, -0.5700,  1.2897],\n","         [ 0.8436, -0.3371,  0.2934,  ..., -0.9852,  0.4547,  0.0955],\n","         ...,\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114],\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114],\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114]],\n","\n","        ...,\n","\n","        [[ 1.1730,  0.5485,  1.3801,  ..., -0.1579, -0.5766, -0.3027],\n","         [ 1.1171,  0.8174,  1.3901,  ...,  0.0906, -0.7520,  0.0843],\n","         [-0.1113,  1.2346,  1.0658,  ...,  0.8423,  0.6119,  2.4125],\n","         ...,\n","         [ 0.2638,  2.1905,  1.8067,  ..., -0.3136,  1.1046,  0.4710],\n","         [ 0.8829, -1.9154,  0.9762,  ...,  1.3012,  0.0798, -0.3831],\n","         [ 0.8311, -0.3905,  0.3757,  ..., -0.0796, -0.0661, -0.1900]],\n","\n","        [[-0.0970,  0.1466,  1.3918,  ..., -0.9419,  1.3662, -0.4475],\n","         [-0.2407,  0.3681,  1.0429,  ...,  0.8047, -0.5183, -0.1752],\n","         [-0.9518,  0.8552, -0.9489,  ..., -0.5057,  1.8131,  0.2992],\n","         ...,\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114],\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114],\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114]],\n","\n","        [[ 0.7183,  1.6994, -0.1695,  ...,  0.0453, -1.0458, -0.4799],\n","         [-0.2407,  0.3681,  1.0429,  ...,  0.8047, -0.5183, -0.1752],\n","         [ 0.9707, -0.8909,  0.4620,  ...,  1.7734, -1.4200, -0.0807],\n","         ...,\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114],\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114],\n","         [-1.1962,  2.8726, -1.2271,  ..., -1.1268, -1.8536,  0.2114]]],\n","       grad_fn=<EmbeddingBackward>)\n","torch.Size([10, 20, 512])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s0Lhx892gmi3"},"source":["### **Linear transformation & 여러 head로 나누기**"]},{"cell_type":"markdown","metadata":{"id":"urXMBRnRgqvw"},"source":["Multi-head attention 내에서 쓰이는 linear transformation matrix들을 정의합니다."]},{"cell_type":"code","metadata":{"id":"9DWKDqgCgfMk","executionInfo":{"status":"ok","timestamp":1613799446052,"user_tz":-540,"elapsed":1263,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["w_q = nn.Linear(d_model, d_model)\r\n","w_k = nn.Linear(d_model, d_model)\r\n","w_v = nn.Linear(d_model, d_model)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"tcLuhda7m-Lm","executionInfo":{"status":"ok","timestamp":1613799446053,"user_tz":-540,"elapsed":1260,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["w_0 = nn.Linear(d_model, d_model)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-vSL7PwnV6k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613802949981,"user_tz":-540,"elapsed":1293,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"ff204614-8b36-4326-d51d-7770c33d5c58"},"source":["q = w_q(batch_emb)  # (B, L, d_model)\r\n","k = w_k(batch_emb)  # (B, L, d_model)\r\n","v = w_v(batch_emb)  # (B, L, d_model)\r\n","\r\n","print(q.shape)\r\n","print(k.shape)\r\n","print(v.shape)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["torch.Size([10, 20, 512])\n","torch.Size([10, 20, 512])\n","torch.Size([10, 20, 512])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wnvlum-LnF1T"},"source":["Q, k, v를 `num_head`개의 차원 분할된 여러 vector로 만듭니다."]},{"cell_type":"code","metadata":{"id":"_tiOKAv9nEli","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613799446055,"user_tz":-540,"elapsed":1256,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"f5b84f6e-088b-46c8-9f2d-e4a5cd404302"},"source":["batch_size = q.shape[0]\r\n","d_k = d_model // num_heads # 실제 논문에서 구현 방식, embedding된 단어 하나의 정보(features)를 여러 개로 쪼개서 multi-head를 구함\r\n","\r\n","q = q.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n","k = k.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n","v = v.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n","\r\n","print(q.shape)\r\n","print(k.shape)\r\n","print(v.shape)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["torch.Size([10, 20, 8, 64])\n","torch.Size([10, 20, 8, 64])\n","torch.Size([10, 20, 8, 64])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5tNb2isfn5Cx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613799446056,"user_tz":-540,"elapsed":1255,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"dea8c765-96e4-4b6f-b131-b27b0dd36831"},"source":["q = q.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n","k = k.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n","v = v.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n","\r\n","print(q.shape)\r\n","print(k.shape)\r\n","print(v.shape)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["torch.Size([10, 8, 20, 64])\n","torch.Size([10, 8, 20, 64])\n","torch.Size([10, 8, 20, 64])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NWrDA5_Sofad"},"source":["### **Scaled dot-product self-attention 구현**"]},{"cell_type":"markdown","metadata":{"id":"w52C4k3Wfl8m"},"source":["각 head에서 실행되는 self-attetion 과정입니다."]},{"cell_type":"code","metadata":{"id":"A5waKr0Hfi2K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613799446057,"user_tz":-540,"elapsed":1253,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"05653bb9-a2f6-47a1-80d1-1ee065122b71"},"source":["attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # (B, num_heads, L, L)\r\n","attn_dists = F.softmax(attn_scores, dim=-1)  # (B, num_heads, L, L)\r\n","\r\n","print(attn_dists)\r\n","print(attn_dists.shape)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["tensor([[[[0.0846, 0.0487, 0.0480,  ..., 0.0371, 0.0371, 0.0371],\n","          [0.0474, 0.0475, 0.0419,  ..., 0.0449, 0.0449, 0.0449],\n","          [0.0416, 0.0432, 0.0746,  ..., 0.0525, 0.0525, 0.0525],\n","          ...,\n","          [0.0357, 0.0621, 0.0570,  ..., 0.0577, 0.0577, 0.0577],\n","          [0.0357, 0.0621, 0.0570,  ..., 0.0577, 0.0577, 0.0577],\n","          [0.0357, 0.0621, 0.0570,  ..., 0.0577, 0.0577, 0.0577]],\n","\n","         [[0.0644, 0.0443, 0.0494,  ..., 0.0351, 0.0351, 0.0351],\n","          [0.0439, 0.0373, 0.0386,  ..., 0.0536, 0.0536, 0.0536],\n","          [0.0704, 0.0452, 0.0316,  ..., 0.0697, 0.0697, 0.0697],\n","          ...,\n","          [0.0511, 0.0473, 0.0432,  ..., 0.0665, 0.0665, 0.0665],\n","          [0.0511, 0.0473, 0.0432,  ..., 0.0665, 0.0665, 0.0665],\n","          [0.0511, 0.0473, 0.0432,  ..., 0.0665, 0.0665, 0.0665]],\n","\n","         [[0.0525, 0.0675, 0.0236,  ..., 0.0370, 0.0370, 0.0370],\n","          [0.0630, 0.0313, 0.0394,  ..., 0.0355, 0.0355, 0.0355],\n","          [0.0435, 0.0525, 0.0636,  ..., 0.0318, 0.0318, 0.0318],\n","          ...,\n","          [0.0382, 0.0698, 0.0362,  ..., 0.0387, 0.0387, 0.0387],\n","          [0.0382, 0.0698, 0.0362,  ..., 0.0387, 0.0387, 0.0387],\n","          [0.0382, 0.0698, 0.0362,  ..., 0.0387, 0.0387, 0.0387]],\n","\n","         ...,\n","\n","         [[0.0364, 0.0323, 0.0360,  ..., 0.0583, 0.0583, 0.0583],\n","          [0.0471, 0.0327, 0.0284,  ..., 0.0422, 0.0422, 0.0422],\n","          [0.0790, 0.0251, 0.0544,  ..., 0.0430, 0.0430, 0.0430],\n","          ...,\n","          [0.0457, 0.0536, 0.0283,  ..., 0.0429, 0.0429, 0.0429],\n","          [0.0457, 0.0536, 0.0283,  ..., 0.0429, 0.0429, 0.0429],\n","          [0.0457, 0.0536, 0.0283,  ..., 0.0429, 0.0429, 0.0429]],\n","\n","         [[0.0536, 0.0272, 0.0570,  ..., 0.0363, 0.0363, 0.0363],\n","          [0.0307, 0.0669, 0.0419,  ..., 0.0397, 0.0397, 0.0397],\n","          [0.0335, 0.0735, 0.0374,  ..., 0.0387, 0.0387, 0.0387],\n","          ...,\n","          [0.0662, 0.0319, 0.0335,  ..., 0.0395, 0.0395, 0.0395],\n","          [0.0662, 0.0319, 0.0335,  ..., 0.0395, 0.0395, 0.0395],\n","          [0.0662, 0.0319, 0.0335,  ..., 0.0395, 0.0395, 0.0395]],\n","\n","         [[0.0369, 0.0462, 0.0508,  ..., 0.0448, 0.0448, 0.0448],\n","          [0.0724, 0.0360, 0.0396,  ..., 0.0452, 0.0452, 0.0452],\n","          [0.0961, 0.0323, 0.0473,  ..., 0.0512, 0.0512, 0.0512],\n","          ...,\n","          [0.0621, 0.0264, 0.0380,  ..., 0.0414, 0.0414, 0.0414],\n","          [0.0621, 0.0264, 0.0380,  ..., 0.0414, 0.0414, 0.0414],\n","          [0.0621, 0.0264, 0.0380,  ..., 0.0414, 0.0414, 0.0414]]],\n","\n","\n","        [[[0.0546, 0.0352, 0.0396,  ..., 0.0503, 0.0503, 0.0503],\n","          [0.0652, 0.0450, 0.0698,  ..., 0.0452, 0.0452, 0.0452],\n","          [0.0400, 0.0308, 0.0513,  ..., 0.0531, 0.0531, 0.0531],\n","          ...,\n","          [0.0879, 0.0555, 0.0239,  ..., 0.0509, 0.0509, 0.0509],\n","          [0.0879, 0.0555, 0.0239,  ..., 0.0509, 0.0509, 0.0509],\n","          [0.0879, 0.0555, 0.0239,  ..., 0.0509, 0.0509, 0.0509]],\n","\n","         [[0.0182, 0.0289, 0.0398,  ..., 0.0525, 0.0525, 0.0525],\n","          [0.0634, 0.0398, 0.0552,  ..., 0.0495, 0.0495, 0.0495],\n","          [0.0450, 0.0617, 0.0342,  ..., 0.0519, 0.0519, 0.0519],\n","          ...,\n","          [0.0552, 0.0429, 0.0291,  ..., 0.0526, 0.0526, 0.0526],\n","          [0.0552, 0.0429, 0.0291,  ..., 0.0526, 0.0526, 0.0526],\n","          [0.0552, 0.0429, 0.0291,  ..., 0.0526, 0.0526, 0.0526]],\n","\n","         [[0.0515, 0.0192, 0.0407,  ..., 0.0499, 0.0499, 0.0499],\n","          [0.0519, 0.0499, 0.0588,  ..., 0.0489, 0.0489, 0.0489],\n","          [0.0913, 0.0292, 0.0573,  ..., 0.0455, 0.0455, 0.0455],\n","          ...,\n","          [0.0425, 0.0503, 0.0631,  ..., 0.0486, 0.0486, 0.0486],\n","          [0.0425, 0.0503, 0.0631,  ..., 0.0486, 0.0486, 0.0486],\n","          [0.0425, 0.0503, 0.0631,  ..., 0.0486, 0.0486, 0.0486]],\n","\n","         ...,\n","\n","         [[0.0306, 0.0640, 0.0551,  ..., 0.0480, 0.0480, 0.0480],\n","          [0.0482, 0.1296, 0.0378,  ..., 0.0466, 0.0466, 0.0466],\n","          [0.0615, 0.0521, 0.0505,  ..., 0.0485, 0.0485, 0.0485],\n","          ...,\n","          [0.0484, 0.0465, 0.0520,  ..., 0.0478, 0.0478, 0.0478],\n","          [0.0484, 0.0465, 0.0520,  ..., 0.0478, 0.0478, 0.0478],\n","          [0.0484, 0.0465, 0.0520,  ..., 0.0478, 0.0478, 0.0478]],\n","\n","         [[0.0677, 0.0922, 0.0968,  ..., 0.0403, 0.0403, 0.0403],\n","          [0.0587, 0.0452, 0.0396,  ..., 0.0513, 0.0513, 0.0513],\n","          [0.0467, 0.0536, 0.0535,  ..., 0.0486, 0.0486, 0.0486],\n","          ...,\n","          [0.0505, 0.0388, 0.0761,  ..., 0.0503, 0.0503, 0.0503],\n","          [0.0505, 0.0388, 0.0761,  ..., 0.0503, 0.0503, 0.0503],\n","          [0.0505, 0.0388, 0.0761,  ..., 0.0503, 0.0503, 0.0503]],\n","\n","         [[0.0414, 0.0496, 0.0548,  ..., 0.0503, 0.0503, 0.0503],\n","          [0.1374, 0.0455, 0.0907,  ..., 0.0413, 0.0413, 0.0413],\n","          [0.0535, 0.0433, 0.0433,  ..., 0.0500, 0.0500, 0.0500],\n","          ...,\n","          [0.0504, 0.0596, 0.0712,  ..., 0.0483, 0.0483, 0.0483],\n","          [0.0504, 0.0596, 0.0712,  ..., 0.0483, 0.0483, 0.0483],\n","          [0.0504, 0.0596, 0.0712,  ..., 0.0483, 0.0483, 0.0483]]],\n","\n","\n","        [[[0.0436, 0.0637, 0.0657,  ..., 0.0410, 0.0410, 0.0410],\n","          [0.0833, 0.0395, 0.0287,  ..., 0.0524, 0.0524, 0.0524],\n","          [0.0451, 0.0270, 0.0318,  ..., 0.0519, 0.0519, 0.0519],\n","          ...,\n","          [0.0723, 0.0333, 0.0563,  ..., 0.0543, 0.0543, 0.0543],\n","          [0.0723, 0.0333, 0.0563,  ..., 0.0543, 0.0543, 0.0543],\n","          [0.0723, 0.0333, 0.0563,  ..., 0.0543, 0.0543, 0.0543]],\n","\n","         [[0.0260, 0.0640, 0.0408,  ..., 0.0551, 0.0551, 0.0551],\n","          [0.0152, 0.0387, 0.0281,  ..., 0.0729, 0.0729, 0.0729],\n","          [0.0357, 0.0523, 0.0278,  ..., 0.0632, 0.0632, 0.0632],\n","          ...,\n","          [0.0599, 0.0225, 0.0258,  ..., 0.0577, 0.0577, 0.0577],\n","          [0.0599, 0.0225, 0.0258,  ..., 0.0577, 0.0577, 0.0577],\n","          [0.0599, 0.0225, 0.0258,  ..., 0.0577, 0.0577, 0.0577]],\n","\n","         [[0.0556, 0.0451, 0.0234,  ..., 0.0487, 0.0487, 0.0487],\n","          [0.0594, 0.0468, 0.0550,  ..., 0.0304, 0.0304, 0.0304],\n","          [0.0555, 0.0378, 0.0279,  ..., 0.0379, 0.0379, 0.0379],\n","          ...,\n","          [0.0446, 0.0610, 0.0611,  ..., 0.0411, 0.0411, 0.0411],\n","          [0.0446, 0.0610, 0.0611,  ..., 0.0411, 0.0411, 0.0411],\n","          [0.0446, 0.0610, 0.0611,  ..., 0.0411, 0.0411, 0.0411]],\n","\n","         ...,\n","\n","         [[0.0694, 0.1211, 0.0630,  ..., 0.0317, 0.0317, 0.0317],\n","          [0.0810, 0.0617, 0.0564,  ..., 0.0455, 0.0455, 0.0455],\n","          [0.0310, 0.0550, 0.0288,  ..., 0.0597, 0.0597, 0.0597],\n","          ...,\n","          [0.0436, 0.0562, 0.0577,  ..., 0.0431, 0.0431, 0.0431],\n","          [0.0436, 0.0562, 0.0577,  ..., 0.0431, 0.0431, 0.0431],\n","          [0.0436, 0.0562, 0.0577,  ..., 0.0431, 0.0431, 0.0431]],\n","\n","         [[0.0401, 0.0373, 0.0793,  ..., 0.0456, 0.0456, 0.0456],\n","          [0.0624, 0.0343, 0.0272,  ..., 0.0530, 0.0530, 0.0530],\n","          [0.0464, 0.0424, 0.0538,  ..., 0.0486, 0.0486, 0.0486],\n","          ...,\n","          [0.0854, 0.0483, 0.0708,  ..., 0.0448, 0.0448, 0.0448],\n","          [0.0854, 0.0483, 0.0708,  ..., 0.0448, 0.0448, 0.0448],\n","          [0.0854, 0.0483, 0.0708,  ..., 0.0448, 0.0448, 0.0448]],\n","\n","         [[0.0518, 0.0488, 0.0371,  ..., 0.0421, 0.0421, 0.0421],\n","          [0.0507, 0.0713, 0.0586,  ..., 0.0439, 0.0439, 0.0439],\n","          [0.0460, 0.0521, 0.0653,  ..., 0.0403, 0.0403, 0.0403],\n","          ...,\n","          [0.0689, 0.0622, 0.0355,  ..., 0.0460, 0.0460, 0.0460],\n","          [0.0689, 0.0622, 0.0355,  ..., 0.0460, 0.0460, 0.0460],\n","          [0.0689, 0.0622, 0.0355,  ..., 0.0460, 0.0460, 0.0460]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0.0284, 0.0379, 0.0393,  ..., 0.0652, 0.0382, 0.0528],\n","          [0.0331, 0.0467, 0.0625,  ..., 0.0698, 0.0282, 0.0639],\n","          [0.0973, 0.0518, 0.0520,  ..., 0.0450, 0.0696, 0.0351],\n","          ...,\n","          [0.0370, 0.0424, 0.0463,  ..., 0.0351, 0.0320, 0.0578],\n","          [0.0301, 0.0556, 0.0425,  ..., 0.0697, 0.0566, 0.0334],\n","          [0.0252, 0.0503, 0.0771,  ..., 0.0512, 0.0365, 0.0514]],\n","\n","         [[0.0575, 0.0361, 0.0587,  ..., 0.0613, 0.0413, 0.0338],\n","          [0.0516, 0.0402, 0.0723,  ..., 0.0387, 0.1151, 0.0475],\n","          [0.0375, 0.0575, 0.0263,  ..., 0.0557, 0.0349, 0.0645],\n","          ...,\n","          [0.0566, 0.0876, 0.0357,  ..., 0.0640, 0.0459, 0.0596],\n","          [0.0573, 0.0266, 0.0667,  ..., 0.0449, 0.0330, 0.0758],\n","          [0.0814, 0.0468, 0.0605,  ..., 0.0545, 0.0631, 0.0373]],\n","\n","         [[0.0539, 0.0464, 0.0523,  ..., 0.0399, 0.0328, 0.0495],\n","          [0.0298, 0.0532, 0.0724,  ..., 0.0375, 0.0356, 0.0461],\n","          [0.0585, 0.0504, 0.0623,  ..., 0.0339, 0.0492, 0.0411],\n","          ...,\n","          [0.0612, 0.0336, 0.0606,  ..., 0.0475, 0.0553, 0.0420],\n","          [0.0283, 0.0427, 0.0571,  ..., 0.0395, 0.0393, 0.0316],\n","          [0.0483, 0.0225, 0.0457,  ..., 0.0779, 0.0480, 0.0507]],\n","\n","         ...,\n","\n","         [[0.0432, 0.0504, 0.0444,  ..., 0.0461, 0.0584, 0.0390],\n","          [0.0637, 0.0567, 0.0526,  ..., 0.0549, 0.0466, 0.0498],\n","          [0.0401, 0.0332, 0.0528,  ..., 0.0375, 0.0864, 0.0313],\n","          ...,\n","          [0.0471, 0.0612, 0.0522,  ..., 0.0718, 0.0521, 0.0300],\n","          [0.0526, 0.0234, 0.0411,  ..., 0.0495, 0.0248, 0.0535],\n","          [0.0696, 0.0604, 0.0340,  ..., 0.0603, 0.0419, 0.0260]],\n","\n","         [[0.0690, 0.0640, 0.0443,  ..., 0.1026, 0.0413, 0.0549],\n","          [0.0495, 0.0631, 0.0395,  ..., 0.0533, 0.0439, 0.0462],\n","          [0.0349, 0.0516, 0.0529,  ..., 0.0467, 0.0553, 0.0653],\n","          ...,\n","          [0.0782, 0.0472, 0.0437,  ..., 0.0354, 0.0324, 0.0398],\n","          [0.0484, 0.0373, 0.0370,  ..., 0.0203, 0.0399, 0.0393],\n","          [0.0492, 0.0413, 0.0585,  ..., 0.0461, 0.0711, 0.0224]],\n","\n","         [[0.0511, 0.0588, 0.0453,  ..., 0.0426, 0.0457, 0.0447],\n","          [0.0716, 0.0547, 0.0635,  ..., 0.0502, 0.0692, 0.0508],\n","          [0.0478, 0.0430, 0.0480,  ..., 0.0453, 0.0576, 0.0682],\n","          ...,\n","          [0.0392, 0.0818, 0.0379,  ..., 0.0391, 0.0492, 0.0401],\n","          [0.0835, 0.0370, 0.0426,  ..., 0.0365, 0.0541, 0.0713],\n","          [0.0719, 0.0487, 0.0594,  ..., 0.0474, 0.0579, 0.0459]]],\n","\n","\n","        [[[0.0486, 0.0392, 0.0588,  ..., 0.0467, 0.0467, 0.0467],\n","          [0.0547, 0.0479, 0.0648,  ..., 0.0590, 0.0590, 0.0590],\n","          [0.0301, 0.0842, 0.0382,  ..., 0.0587, 0.0587, 0.0587],\n","          ...,\n","          [0.0522, 0.0402, 0.0561,  ..., 0.0597, 0.0597, 0.0597],\n","          [0.0522, 0.0402, 0.0561,  ..., 0.0597, 0.0597, 0.0597],\n","          [0.0522, 0.0402, 0.0561,  ..., 0.0597, 0.0597, 0.0597]],\n","\n","         [[0.0436, 0.0404, 0.0863,  ..., 0.0443, 0.0443, 0.0443],\n","          [0.0446, 0.0658, 0.0434,  ..., 0.0352, 0.0352, 0.0352],\n","          [0.0529, 0.0716, 0.0680,  ..., 0.0670, 0.0670, 0.0670],\n","          ...,\n","          [0.0431, 0.0678, 0.0460,  ..., 0.0672, 0.0672, 0.0672],\n","          [0.0431, 0.0678, 0.0460,  ..., 0.0672, 0.0672, 0.0672],\n","          [0.0431, 0.0678, 0.0460,  ..., 0.0672, 0.0672, 0.0672]],\n","\n","         [[0.0464, 0.0644, 0.0298,  ..., 0.0742, 0.0742, 0.0742],\n","          [0.0491, 0.0295, 0.0418,  ..., 0.0744, 0.0744, 0.0744],\n","          [0.0382, 0.0432, 0.0441,  ..., 0.0577, 0.0577, 0.0577],\n","          ...,\n","          [0.0346, 0.0402, 0.0481,  ..., 0.0396, 0.0396, 0.0396],\n","          [0.0346, 0.0402, 0.0481,  ..., 0.0396, 0.0396, 0.0396],\n","          [0.0346, 0.0402, 0.0481,  ..., 0.0396, 0.0396, 0.0396]],\n","\n","         ...,\n","\n","         [[0.0578, 0.1221, 0.0654,  ..., 0.0430, 0.0430, 0.0430],\n","          [0.0316, 0.0365, 0.0662,  ..., 0.0525, 0.0525, 0.0525],\n","          [0.0385, 0.0649, 0.0185,  ..., 0.0622, 0.0622, 0.0622],\n","          ...,\n","          [0.0387, 0.0669, 0.0541,  ..., 0.0432, 0.0432, 0.0432],\n","          [0.0387, 0.0669, 0.0541,  ..., 0.0432, 0.0432, 0.0432],\n","          [0.0387, 0.0669, 0.0541,  ..., 0.0432, 0.0432, 0.0432]],\n","\n","         [[0.0429, 0.0373, 0.0523,  ..., 0.0406, 0.0406, 0.0406],\n","          [0.0948, 0.0356, 0.0421,  ..., 0.0564, 0.0564, 0.0564],\n","          [0.0401, 0.0310, 0.0498,  ..., 0.0433, 0.0433, 0.0433],\n","          ...,\n","          [0.0514, 0.0508, 0.0324,  ..., 0.0435, 0.0435, 0.0435],\n","          [0.0514, 0.0508, 0.0324,  ..., 0.0435, 0.0435, 0.0435],\n","          [0.0514, 0.0508, 0.0324,  ..., 0.0435, 0.0435, 0.0435]],\n","\n","         [[0.0616, 0.0317, 0.0238,  ..., 0.0401, 0.0401, 0.0401],\n","          [0.0431, 0.0489, 0.0234,  ..., 0.0608, 0.0608, 0.0608],\n","          [0.0371, 0.0456, 0.0557,  ..., 0.0431, 0.0431, 0.0431],\n","          ...,\n","          [0.0583, 0.0643, 0.0403,  ..., 0.0461, 0.0461, 0.0461],\n","          [0.0583, 0.0643, 0.0403,  ..., 0.0461, 0.0461, 0.0461],\n","          [0.0583, 0.0643, 0.0403,  ..., 0.0461, 0.0461, 0.0461]]],\n","\n","\n","        [[[0.0602, 0.0442, 0.0768,  ..., 0.0668, 0.0668, 0.0668],\n","          [0.0436, 0.0442, 0.0309,  ..., 0.0544, 0.0544, 0.0544],\n","          [0.0351, 0.0658, 0.0378,  ..., 0.0584, 0.0584, 0.0584],\n","          ...,\n","          [0.0517, 0.0370, 0.0316,  ..., 0.0549, 0.0549, 0.0549],\n","          [0.0517, 0.0370, 0.0316,  ..., 0.0549, 0.0549, 0.0549],\n","          [0.0517, 0.0370, 0.0316,  ..., 0.0549, 0.0549, 0.0549]],\n","\n","         [[0.0304, 0.0658, 0.0247,  ..., 0.0740, 0.0740, 0.0740],\n","          [0.0970, 0.0669, 0.0515,  ..., 0.0358, 0.0358, 0.0358],\n","          [0.0531, 0.0631, 0.0303,  ..., 0.0623, 0.0623, 0.0623],\n","          ...,\n","          [0.0339, 0.0638, 0.0186,  ..., 0.0632, 0.0632, 0.0632],\n","          [0.0339, 0.0638, 0.0186,  ..., 0.0632, 0.0632, 0.0632],\n","          [0.0339, 0.0638, 0.0186,  ..., 0.0632, 0.0632, 0.0632]],\n","\n","         [[0.0598, 0.0515, 0.0664,  ..., 0.0486, 0.0486, 0.0486],\n","          [0.0659, 0.0255, 0.0323,  ..., 0.0642, 0.0642, 0.0642],\n","          [0.0809, 0.0403, 0.0532,  ..., 0.0391, 0.0391, 0.0391],\n","          ...,\n","          [0.0352, 0.0437, 0.0287,  ..., 0.0431, 0.0431, 0.0431],\n","          [0.0352, 0.0437, 0.0287,  ..., 0.0431, 0.0431, 0.0431],\n","          [0.0352, 0.0437, 0.0287,  ..., 0.0431, 0.0431, 0.0431]],\n","\n","         ...,\n","\n","         [[0.0410, 0.0550, 0.0639,  ..., 0.0440, 0.0440, 0.0440],\n","          [0.0724, 0.0398, 0.0440,  ..., 0.0573, 0.0573, 0.0573],\n","          [0.0721, 0.0452, 0.0587,  ..., 0.0443, 0.0443, 0.0443],\n","          ...,\n","          [0.0652, 0.0653, 0.0631,  ..., 0.0422, 0.0422, 0.0422],\n","          [0.0652, 0.0653, 0.0631,  ..., 0.0422, 0.0422, 0.0422],\n","          [0.0652, 0.0653, 0.0631,  ..., 0.0422, 0.0422, 0.0422]],\n","\n","         [[0.0548, 0.0405, 0.0489,  ..., 0.0458, 0.0458, 0.0458],\n","          [0.0481, 0.0341, 0.0540,  ..., 0.0541, 0.0541, 0.0541],\n","          [0.0367, 0.1210, 0.0354,  ..., 0.0632, 0.0632, 0.0632],\n","          ...,\n","          [0.0692, 0.0462, 0.0762,  ..., 0.0396, 0.0396, 0.0396],\n","          [0.0692, 0.0462, 0.0762,  ..., 0.0396, 0.0396, 0.0396],\n","          [0.0692, 0.0462, 0.0762,  ..., 0.0396, 0.0396, 0.0396]],\n","\n","         [[0.0542, 0.0462, 0.0360,  ..., 0.0642, 0.0642, 0.0642],\n","          [0.0335, 0.0464, 0.0405,  ..., 0.0577, 0.0577, 0.0577],\n","          [0.0840, 0.0413, 0.0416,  ..., 0.0413, 0.0413, 0.0413],\n","          ...,\n","          [0.0301, 0.0595, 0.0659,  ..., 0.0427, 0.0427, 0.0427],\n","          [0.0301, 0.0595, 0.0659,  ..., 0.0427, 0.0427, 0.0427],\n","          [0.0301, 0.0595, 0.0659,  ..., 0.0427, 0.0427, 0.0427]]]],\n","       grad_fn=<SoftmaxBackward>)\n","torch.Size([10, 8, 20, 20])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7megouWpgCck","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613799446058,"user_tz":-540,"elapsed":1251,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"86c73758-ccf8-4eaf-ceae-defb10086296"},"source":["attn_values = torch.matmul(attn_dists, v)  # (B, num_heads, L, d_k)\r\n","\r\n","print(attn_values.shape)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["torch.Size([10, 8, 20, 64])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LmSTaymdg-P_"},"source":["### **각 head의 결과물 병합**"]},{"cell_type":"markdown","metadata":{"id":"YSdQZCk0hCNd"},"source":["각 head의 결과물을 concat하고 동일 차원으로 linear transformation합니다."]},{"cell_type":"code","metadata":{"id":"eaK0bpMGhQZ2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613799446059,"user_tz":-540,"elapsed":1248,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"3c3e9565-7fa1-45d4-e30d-258e8ed192df"},"source":["attn_values = attn_values.transpose(1, 2)  # (B, L, num_heads, d_k)\r\n","attn_values = attn_values.contiguous().view(batch_size, -1, d_model)  # (B, L, d_model) \r\n","# congiguous() = 메모리에 연속적으로 배열된 tensor를 새로 반환함\r\n","\r\n","print(attn_values.shape)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["torch.Size([10, 20, 512])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LTng_2SXhdH1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613799446059,"user_tz":-540,"elapsed":1246,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"c16ab72c-1ebe-4b9f-c2c6-757081275bd9"},"source":["outputs = w_0(attn_values)\r\n","\r\n","print(outputs)\r\n","print(outputs.shape)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["tensor([[[-5.6372e-02,  2.0260e-02, -2.0673e-01,  ..., -1.0473e-01,\n","           3.9225e-02, -1.7363e-02],\n","         [-4.0734e-02,  3.6285e-02, -1.6315e-01,  ..., -9.6915e-02,\n","           9.2038e-02,  2.4939e-02],\n","         [-5.6946e-02,  5.4392e-02, -1.4964e-01,  ..., -7.5285e-02,\n","           4.9044e-02, -1.8751e-02],\n","         ...,\n","         [-5.0095e-02,  7.5420e-02, -1.6180e-01,  ..., -7.3211e-02,\n","           5.2999e-02, -5.5118e-03],\n","         [-5.0095e-02,  7.5420e-02, -1.6180e-01,  ..., -7.3211e-02,\n","           5.2999e-02, -5.5118e-03],\n","         [-5.0095e-02,  7.5420e-02, -1.6180e-01,  ..., -7.3211e-02,\n","           5.2999e-02, -5.5118e-03]],\n","\n","        [[ 5.4670e-02,  9.4746e-02,  6.1076e-02,  ..., -1.5567e-01,\n","          -1.8943e-02, -9.3740e-02],\n","         [ 3.8374e-02, -1.0920e-04,  1.8537e-02,  ..., -1.5706e-01,\n","          -2.7648e-02, -4.2522e-02],\n","         [ 6.9620e-02,  8.9878e-02,  3.2770e-02,  ..., -1.3834e-01,\n","           3.0849e-02, -7.5695e-02],\n","         ...,\n","         [ 8.5678e-02,  6.4007e-02,  5.3716e-02,  ..., -1.5133e-01,\n","           1.1544e-02, -7.3548e-02],\n","         [ 8.5678e-02,  6.4007e-02,  5.3716e-02,  ..., -1.5133e-01,\n","           1.1544e-02, -7.3548e-02],\n","         [ 8.5678e-02,  6.4007e-02,  5.3716e-02,  ..., -1.5133e-01,\n","           1.1544e-02, -7.3548e-02]],\n","\n","        [[ 5.2123e-02, -5.3791e-02, -9.2772e-02,  ..., -1.3960e-01,\n","           1.8578e-02, -1.8347e-01],\n","         [ 6.9659e-02, -7.0415e-02, -6.1618e-02,  ..., -1.2882e-01,\n","           6.9216e-02, -2.1816e-01],\n","         [ 7.2027e-02, -1.0833e-01, -5.3726e-02,  ..., -5.7624e-02,\n","           6.0266e-02, -2.1120e-01],\n","         ...,\n","         [ 6.2799e-02, -7.9708e-02, -6.8753e-02,  ..., -1.4838e-01,\n","           1.0135e-03, -1.9850e-01],\n","         [ 6.2799e-02, -7.9708e-02, -6.8753e-02,  ..., -1.4838e-01,\n","           1.0135e-03, -1.9850e-01],\n","         [ 6.2799e-02, -7.9708e-02, -6.8753e-02,  ..., -1.4838e-01,\n","           1.0135e-03, -1.9850e-01]],\n","\n","        ...,\n","\n","        [[ 6.2532e-02, -1.6858e-01, -1.3279e-01,  ..., -3.9162e-03,\n","          -5.3286e-02, -1.7490e-02],\n","         [ 1.0193e-01, -1.8920e-01, -1.5329e-01,  ..., -4.0843e-04,\n","           1.3460e-02, -4.8383e-02],\n","         [ 1.0872e-01, -1.9899e-01, -1.3915e-01,  ..., -1.1259e-02,\n","          -1.1284e-01, -9.8785e-02],\n","         ...,\n","         [ 9.1149e-02, -1.8724e-01, -1.6369e-01,  ..., -7.1843e-03,\n","          -5.2771e-02, -6.4171e-02],\n","         [ 7.8070e-02, -2.2499e-01, -1.2789e-01,  ...,  2.0326e-02,\n","           1.0899e-02, -3.4516e-02],\n","         [ 9.2537e-02, -1.8569e-01, -9.4434e-02,  ...,  2.3309e-02,\n","          -2.7485e-02,  1.3349e-02]],\n","\n","        [[ 1.3859e-02, -7.4873e-02, -1.3903e-02,  ..., -1.3878e-01,\n","          -3.0339e-02, -1.2744e-02],\n","         [-1.0603e-02, -2.9747e-02,  4.8680e-02,  ..., -1.9047e-01,\n","          -2.3701e-02,  1.2085e-02],\n","         [-1.0041e-02, -5.6498e-02,  3.2807e-02,  ..., -1.2677e-01,\n","           1.5997e-02, -4.6985e-02],\n","         ...,\n","         [-6.7663e-03, -2.9975e-02, -5.1858e-03,  ..., -1.4982e-01,\n","           5.0037e-02, -4.9370e-02],\n","         [-6.7663e-03, -2.9975e-02, -5.1858e-03,  ..., -1.4982e-01,\n","           5.0037e-02, -4.9370e-02],\n","         [-6.7663e-03, -2.9975e-02, -5.1858e-03,  ..., -1.4982e-01,\n","           5.0037e-02, -4.9370e-02]],\n","\n","        [[-6.3024e-05, -1.4604e-01, -2.9787e-02,  ..., -1.3206e-01,\n","          -1.8552e-02,  1.2540e-02],\n","         [ 5.2486e-02, -1.1446e-01, -5.7766e-02,  ..., -1.4201e-01,\n","          -9.5731e-03,  8.7590e-02],\n","         [ 3.2582e-02, -1.1849e-01, -3.5648e-02,  ..., -1.8565e-01,\n","          -2.3304e-04,  4.1326e-02],\n","         ...,\n","         [ 2.1694e-02, -1.0673e-01, -5.0157e-02,  ..., -1.6525e-01,\n","          -6.3927e-02,  4.4107e-03],\n","         [ 2.1694e-02, -1.0673e-01, -5.0157e-02,  ..., -1.6525e-01,\n","          -6.3927e-02,  4.4107e-03],\n","         [ 2.1694e-02, -1.0673e-01, -5.0157e-02,  ..., -1.6525e-01,\n","          -6.3927e-02,  4.4107e-03]]], grad_fn=<AddBackward0>)\n","torch.Size([10, 20, 512])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"goX70VKqhxQH"},"source":["### **전체 코드**"]},{"cell_type":"markdown","metadata":{"id":"WtNyV7mMj7V_"},"source":["위의 과정을 모두 합쳐 하나의 Multi-head attention 모듈을 구현하겠습니다."]},{"cell_type":"code","metadata":{"id":"U_kNhOTrkBHm","executionInfo":{"status":"ok","timestamp":1613799446060,"user_tz":-540,"elapsed":1245,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["class MultiheadAttention(nn.Module):\r\n","  def __init__(self):\r\n","    super(MultiheadAttention, self).__init__()\r\n","\r\n","    # Q, K, V learnable matrices\r\n","    self.w_q = nn.Linear(d_model, d_model)\r\n","    self.w_k = nn.Linear(d_model, d_model)\r\n","    self.w_v = nn.Linear(d_model, d_model)\r\n","\r\n","    # Linear transformation for concatenated outputs\r\n","    self.w_0 = nn.Linear(d_model, d_model)\r\n","\r\n","  def forward(self, q, k, v):\r\n","    batch_size = q.shape[0]\r\n","\r\n","    q = self.w_q(q)  # (B, L, d_model)\r\n","    k = self.w_k(k)  # (B, L, d_model)\r\n","    v = self.w_v(v)  # (B, L, d_model)\r\n","\r\n","    q = q.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n","    k = k.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n","    v = v.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n","\r\n","    q = q.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n","    k = k.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n","    v = v.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n","\r\n","    attn_values = self.self_attention(q, k, v)  # (B, num_heads, L, d_k)\r\n","    attn_values = attn_values.transpose(1, 2).contiguous().view(batch_size, -1, d_model)  # (B, L, num_heads, d_k) => (B, L, d_model)\r\n","\r\n","    return self.w_0(attn_values)\r\n","\r\n","  def self_attention(self, q, k, v):\r\n","    attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # (B, num_heads, L, L)\r\n","    attn_dists = F.softmax(attn_scores, dim=-1)  # (B, num_heads, L, L)\r\n","\r\n","    attn_values = torch.matmul(attn_dists, v)  # (B, num_heads, L, d_k)\r\n","\r\n","    return attn_values"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"jYLuu_9alQxT","executionInfo":{"status":"ok","timestamp":1613799446061,"user_tz":-540,"elapsed":1244,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["multihead_attn = MultiheadAttention()\r\n","\r\n","outputs = multihead_attn(batch_emb, batch_emb, batch_emb)  # (B, L, d_model)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"KMiXlYjSlTfB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613799446372,"user_tz":-540,"elapsed":1553,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"1f67f2dd-a8fd-4e0b-9386-d3ded6d745eb"},"source":["print(outputs)\r\n","print(outputs.shape)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["tensor([[[-0.0404,  0.0224,  0.2301,  ...,  0.0857,  0.1325,  0.1532],\n","         [-0.0600,  0.0390,  0.1469,  ...,  0.1620,  0.1024,  0.2262],\n","         [-0.0850,  0.0875,  0.1645,  ...,  0.0564,  0.1324,  0.1759],\n","         ...,\n","         [-0.0516,  0.0557,  0.1825,  ...,  0.1076,  0.1603,  0.1408],\n","         [-0.0516,  0.0557,  0.1825,  ...,  0.1076,  0.1603,  0.1408],\n","         [-0.0516,  0.0557,  0.1825,  ...,  0.1076,  0.1603,  0.1408]],\n","\n","        [[-0.2245, -0.0291,  0.2946,  ..., -0.0619,  0.1280,  0.2630],\n","         [-0.2048, -0.0114,  0.3183,  ..., -0.0680,  0.1399,  0.2983],\n","         [-0.1814, -0.0591,  0.3207,  ..., -0.0459,  0.1685,  0.2697],\n","         ...,\n","         [-0.1671, -0.0630,  0.2798,  ..., -0.0554,  0.1066,  0.2606],\n","         [-0.1671, -0.0630,  0.2798,  ..., -0.0554,  0.1066,  0.2606],\n","         [-0.1671, -0.0630,  0.2798,  ..., -0.0554,  0.1066,  0.2606]],\n","\n","        [[-0.0944, -0.0834,  0.1834,  ..., -0.0875,  0.0301,  0.2550],\n","         [-0.1133, -0.0635,  0.2359,  ..., -0.1164,  0.0201,  0.2841],\n","         [-0.0700, -0.0269,  0.1857,  ..., -0.0179, -0.0375,  0.2838],\n","         ...,\n","         [-0.1024, -0.0343,  0.1953,  ..., -0.0199,  0.0154,  0.2639],\n","         [-0.1024, -0.0343,  0.1953,  ..., -0.0199,  0.0154,  0.2639],\n","         [-0.1024, -0.0343,  0.1953,  ..., -0.0199,  0.0154,  0.2639]],\n","\n","        ...,\n","\n","        [[ 0.1217,  0.0225,  0.0401,  ...,  0.1618,  0.1627, -0.0310],\n","         [ 0.1428,  0.0289,  0.0159,  ...,  0.1424,  0.1667, -0.0206],\n","         [ 0.1084, -0.0068,  0.0173,  ...,  0.1300,  0.2115, -0.0303],\n","         ...,\n","         [ 0.1149,  0.0241,  0.0205,  ...,  0.1035,  0.2052, -0.0438],\n","         [ 0.1384, -0.0022,  0.0262,  ...,  0.1427,  0.1462, -0.0626],\n","         [ 0.0858, -0.0218, -0.0091,  ...,  0.1365,  0.1292, -0.0792]],\n","\n","        [[ 0.0736, -0.0242,  0.0604,  ...,  0.1208,  0.0870, -0.0170],\n","         [ 0.0351, -0.0903,  0.0367,  ...,  0.0680,  0.0882,  0.0551],\n","         [ 0.0929, -0.1034,  0.0850,  ...,  0.0228,  0.1251,  0.0213],\n","         ...,\n","         [ 0.0895, -0.0065,  0.0334,  ...,  0.0815,  0.1242,  0.0338],\n","         [ 0.0895, -0.0065,  0.0334,  ...,  0.0815,  0.1242,  0.0338],\n","         [ 0.0895, -0.0065,  0.0334,  ...,  0.0815,  0.1242,  0.0338]],\n","\n","        [[-0.0275,  0.0899,  0.1361,  ...,  0.0629,  0.1066, -0.0287],\n","         [-0.0185,  0.0371,  0.0821,  ...,  0.0737,  0.0942,  0.0873],\n","         [ 0.0170,  0.1365,  0.0736,  ...,  0.1262,  0.0519, -0.0030],\n","         ...,\n","         [ 0.0414,  0.0497,  0.0994,  ...,  0.0780,  0.0788,  0.0392],\n","         [ 0.0414,  0.0497,  0.0994,  ...,  0.0780,  0.0788,  0.0392],\n","         [ 0.0414,  0.0497,  0.0994,  ...,  0.0780,  0.0788,  0.0392]]],\n","       grad_fn=<AddBackward0>)\n","torch.Size([10, 20, 512])\n"],"name":"stdout"}]}]}