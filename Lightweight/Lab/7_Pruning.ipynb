{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7_Pruning.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QB3VdM2CRMIC"},"source":["## 주안점\r\n","#### Pruning 전/후 model size 비교\r\n","\r\n","- [참고] https://pytorch.org/tutorials/intermediate/pruning_tutorial.html"]},{"cell_type":"code","metadata":{"id":"f5ti_Q1t1UBA"},"source":["import os\n","import time\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import torchvision\n","from torchvision import transforms"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4zbgc4NBMq_o"},"source":["# 모델 생성\n","먼저 프루닝을 수행하기 위한 간단한 모델을 생성하고 훈련시켜 봅시다.\n","\n","모델은 LeNet5, 데이터는 Mnist를 사용하겠습니다."]},{"cell_type":"code","metadata":{"id":"JMSlmDCGUIYX"},"source":["train_loader = DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n","                                                    transform=transforms.Compose([transforms.ToTensor(),\n","                                                                        transforms.Normalize((0.1307,), (0.3081,))\n","                                                    ])),\n","               batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n","\n","test_loader = DataLoader(torchvision.datasets.MNIST('../data', train=False, \n","                                                    transform=transforms.Compose([transforms.ToTensor(),\n","                                                                        transforms.Normalize((0.1307,), (0.3081,))\n","                                                    ])),\n","              batch_size=64, shuffle=False, num_workers=1, pin_memory=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"39pOm4tjUrV6"},"source":["images, labels = next(iter(train_loader))\n","\n","print(images.shape)\n","print(labels.shape)\n","\n","figure = plt.figure()\n","num_of_images = 20\n","for index in range(1, num_of_images + 1):\n","    plt.subplot(6, 10, index)\n","    plt.axis('off')\n","    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')\n","print(labels[1:21])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-6SmhckMTvO"},"source":["class LeNet(nn.Module):\n","    def __init__(self):\n","        super(LeNet, self).__init__()\n","        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n","        self.conv1 = nn.Conv2d(1, 6, 3)\n","        self.conv2 = nn.Conv2d(6, 16, 3)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n","        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","        x = x.view(-1, int(x.nelement() / x.shape[0]))\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = LeNet().to(device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTJNZzy8MXfo"},"source":["def train(args, model, device, train_loader, optimizer, criterion, epoch):\n","    \"\"\" Train the model with given dataset\n","    \n","    Args:\n","        args: args like log interval\n","        model: ResNet model to train\n","        device: CPU/GPU\n","        train_loader: dataset iterator\n","        optimizer: optimizer to update weights\n","        epoch: number of epochs to train for\n","    \"\"\"\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % args[\"log_interval\"] == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"87FmftGKSIto"},"source":["batch_size = 64\r\n","epochs = 10\r\n","lr = 0.001\r\n","momentum = 0.9\r\n","seed = 1\r\n","log_interval = 500\r\n","save_model = True\r\n","no_cuda = False\r\n","\r\n","use_cuda = not no_cuda and torch.cuda.is_available()\r\n","torch.manual_seed(seed)\r\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n","model = LeNet().to(device)\r\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n","criterion = nn.CrossEntropyLoss()\r\n","args = {}\r\n","args[\"log_interval\"] = log_interval\r\n","for epoch in range(1, epochs + 1):\r\n","    train(args, model, device, train_loader, optimizer, criterion, epoch)\r\n","\r\n","if (save_model):\r\n","    torch.save(model.state_dict(),\"mnist_cnn.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z9ftFwREVifL"},"source":["def print_size_of_model(model):\n","    \"\"\" Print the size of the model.\n","    \n","    Args:\n","        model: model whose size needs to be determined\n","\n","    \"\"\"\n","    torch.save(model.state_dict(), \"temp.p\")\n","    print('Size of the model(MB):', os.path.getsize(\"temp.p\")/1e6)\n","    os.remove('temp.p')\n","  \n","print_size_of_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qpvyGuZtVjN6"},"source":["def test(model, device, test_loader, quantize=False, fbgemm=False):\n","    model.to(device)\n","    model.eval()\n","    print(model)\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            st = time.time()\n","            output = model(data)\n","            et = time.time()\n","            test_loss += F.nll_loss(F.log_softmax(output, dim=-1), target, reduction='sum').item() # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    \n","    print(\"========================================= PERFORMANCE =============================================\")\n","    print_size_of_model(model)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n","    print(\"====================================================================================================\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"319h_l8HW4zt"},"source":["device = 'cpu'\n","test(model=model, device=device, test_loader=test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4wFFtDTJMp7s"},"source":["# 레이어 weight 확인\n","먼저 생성된 모델의 첫 번째 레이어를 구성하는 파라미터 들을 확인해봅시다.\n","weight와 bias로 구성이 되어 있는 것을 확인할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"zmbHBZEuM2oH"},"source":["module = model.conv1\n","print(list(module.named_parameters()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"itF_G9Uf16FW"},"source":["output_orig = model(images[:1])\r\n","print(f\"original output: {output_orig}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"38gFa0uzhnfm"},"source":["# Unstructured Pruning\n","기본적인 프루닝 방법은 스칼라 단위의 값(=하나의 숫자)에 대해 프루닝을 하는 것입니다.\n","\n","Pytorch에서 제공하는 prune method를 이용하여 이를 수행해보겠습니다.\n","프루닝할 값을 고르는 방법 또한 여러가지입니다만, 우선 random으로 선택하는 방식을 적용해 보겠습니다."]},{"cell_type":"code","metadata":{"id":"652QSScGhxov"},"source":["import torch.nn.utils.prune as prune"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mbdyH0jjzgsj"},"source":["prune.random_unstructured(module, name=\"weight\", amount=0.3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVsSTYoXzi-J"},"source":["print(list(module.named_parameters()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xz7vmYxmz_JC"},"source":["기존 레이어는 'weight', 'bias'로 구성이 되어있었던 파라미터가 'weight_orig', 'bias'라는 이름으로 바뀐 것을 볼 수 있습니다. 'weight'가 'weight_orig'라는 이름으로 바뀌었네요\n","\n","하지만 값은 전혀 변한 것이 없습니다. 그러면 무엇이 수행이 된 것일까요?"]},{"cell_type":"code","metadata":{"id":"UMADExKO0pp-"},"source":["print(list(module.named_buffers()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VZ2DCH-P1Jot"},"source":["prune 함수를 수행하고 나면, 레이어의 named_buffers()에 'weight_mask'라는 새로운 파라미터가 하나 생성된 것을 볼 수 있습니다.\n","\n","\n","프루닝이라면 일반적으로 특정 값을 0으로 만들어 영향력을 없애는 것으로 생각할 수 있습니다. 하지만 pytorch에서는 직접 값을 바로 0으로 바꾸는 대신, mask 텐서를 추가로 생성하여 프루닝을 수행하게 됩니다. 삭제할 값을 0, 보존할 값을 1로 설정한 mask 텐서를 생성한 후, 실제 계산을 수행할때 mask와 weight를 원소별로 곱한 텐서를 활용하게 되지요.\n","\n","pruning mask가 적용된 weight의 결과는 레이어의 weight 속성에서 확인할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"Eua36t5M1WZP"},"source":["print(module.weight)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4s3tjkgfFtN1"},"source":["그러면 기존 모델의 출력값과 첫번째 레이어를 가지치기한 모델의 결과를 비교해봅시다.\r\n","값에 차이가 생긴 것을 볼 수가 있습니다."]},{"cell_type":"code","metadata":{"id":"tkPZQElOEr7v"},"source":["output_pruned_conv1 = model(images[:1])\r\n","print(f\"original output: {output_orig}\")\r\n","print(f\"pruned weight output: {output_pruned_conv1}\")\r\n","print(f\"difference: {output_orig - output_pruned_conv1}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RgdIeWxR2o8S"},"source":["전체 성능 테스트에서도 어느정도 성능이 떨어진 것을 볼 수 있습니다."]},{"cell_type":"code","metadata":{"id":"-mKTbf8B2hRV"},"source":["device = 'cpu'\r\n","test(model=model, device=device, test_loader=test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"adkR97o3DvzH"},"source":["이렇게 weight에 대해 프루닝을 적용해 보았습니다!\r\n","\r\n","이번에는 또 다른 parameter인 bias에 pruning을 적용해보겠습니다. random으로 값을 선택하여 가지치기한 weight와는 다르게, bias는 값이 작은 순서대로 프루닝을 수행해봅시다."]},{"cell_type":"code","metadata":{"id":"AOCYgVzhD_VR"},"source":["prune.l1_unstructured(module, name=\"bias\", amount=3)  # amount를 float으로 입력하면 해당 비율만큼, int로 입력할 경우 해당 갯수만큼 값을 선택하여 가지치기합니다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t6LcNI3fEf9o"},"source":["print(list(module.named_parameters()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6v-5Hsr6GM9O"},"source":["print(list(module.named_buffers()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9-gvidouGOU4"},"source":["print(module.bias)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4iUr-p3iSmoG"},"source":["device = 'cpu'\r\n","test(model=model, device=device, test_loader=test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oCImByoP3L2A"},"source":["# Model 크기 비교\r\n","프루닝 된 모델의 크기를 출력하면, 프루닝되기 전의 모델보다 모델의 사이즈가 커진 것을 확인할 수 있습니다.\r\n","\r\n","상식적으로 가지치기가 되었다면 모델의 크기가 줄어들어야 할 텐데, 오히려 모델의 용량이 늘어난 것은 왜일까요?"]},{"cell_type":"code","metadata":{"id":"gK1SgI8GSmrb"},"source":["print_size_of_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"10BfjmQE4UC3"},"source":["# 프루닝 영구 적용하기\r\n","Pytorch에서 제공하는 prune method는 mask를 생성하는 방식으로 프루닝을 수행하는 것을 볼 수 있었습니다.\r\n","\r\n","이 때 원본 모델의 parameter는 \"weight_orig\", \"bias_orig\"과 같은 형태로 보존하는 것 또한 볼 수 있었습니다."]},{"cell_type":"code","metadata":{"id":"btaAHlYH9StX"},"source":["print(list(module.named_parameters()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZPkpsq2ELNUe"},"source":["이러한 프루닝을 수행한 후 더 이상 원본 파라미터가 필요하지 않을 때, pruning을 영구히 적용하는 방법을 알아봅시다.\r\n","\r\n","prune.remove 함수를 사용하면, 기존의 원본 파라미터를 삭제하고 이를 prune이 적용된 weight를 교체하게 됩니다."]},{"cell_type":"code","metadata":{"id":"Kas8wU-r4Nwo"},"source":["prune.remove(module, 'weight')\r\n","print(list(module.named_parameters()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VuieF2khL2DR"},"source":["weight에 해당하는 mask 또한 없어진 것을 볼 수 있습니다."]},{"cell_type":"code","metadata":{"id":"_9G_h027_rpO"},"source":["print(list(module.named_buffers()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Ow-G8pAMYei"},"source":["마찬가지로 bias에 해당하는 prune도 영구 적용시켜보겠습니다."]},{"cell_type":"code","metadata":{"id":"6y1uTaSF_mCC"},"source":["prune.remove(module, 'bias')\r\n","print(list(module.named_parameters()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghABEy1qHhNJ"},"source":["print(list(module.named_buffers()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pKEH-6IhMkRu"},"source":["mask를 제거하고 pruned weight를 영구히 적용시키니, 모델의 사이즈 또한 원래의 모델 사이즈와 동일해진 것을 볼 수 있습니다."]},{"cell_type":"code","metadata":{"id":"4D4_phTOHx7B"},"source":["print_size_of_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnAnQ6c9MzyV"},"source":[""],"execution_count":null,"outputs":[]}]}